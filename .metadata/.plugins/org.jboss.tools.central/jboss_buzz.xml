<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Containerize and deploy Strapi applications on Kubernetes and Red Hat OpenShift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/LW4jocGRXEk/" /><category term="Containers" /><category term="JavaScript" /><category term="Kubernetes" /><category term="Node.js" /><category term="containerization" /><category term="Deploying Strapi" /><category term="openshift" /><category term="Strapi" /><author><name>Joel Lord</name></author><id>https://developers.redhat.com/blog/?p=874347</id><updated>2021-04-09T07:00:16Z</updated><published>2021-04-09T07:00:16Z</published><content type="html">&lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://strapi.io/"&gt;Strapi&lt;/a&gt; is the leading open-source headless content management system (CMS). It’s 100% &lt;a target="_blank" rel="nofollow" href="/topics/javascript"&gt;JavaScript&lt;/a&gt;, fully customizable, and takes a developer-first approach. Strapi provides you with an interface to create and manage all the resources for your website. You can then build a front end to connect to your Strapi API with your favorite tools and frameworks. Content editors can use the friendly administration panel to manage and distribute content. Strapi is also based on a plugin system, which makes the CMS flexible and extensible.&lt;/p&gt; &lt;p&gt;Once you&amp;#8217;ve built your resources with Strapi&amp;#8217;s administration panel and designed a nice front end to serve the content, you will need to deploy the application somewhere. This article shows you how to deploy a Strapi application on a &lt;a target="_blank" rel="nofollow" href="/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; or &lt;a target="_blank" rel="nofollow" href="/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; cluster.&lt;/p&gt; &lt;h2&gt;Step 1: Set up the development environment&lt;/h2&gt; &lt;p&gt;To use Strapi in a containerized development environment, you will need three independent containers: One to run the database, another for Strapi, and one for the front end. This section shows you how to set up the three containers you will use in development.&lt;/p&gt; &lt;h3&gt;Initial setup&lt;/h3&gt; &lt;p&gt;The database and back-end servers must be able to communicate. You can use a Docker network for this communication. Create your network with the following command:&lt;/p&gt; &lt;pre&gt;$ docker network create strapi &lt;/pre&gt; &lt;p&gt;You will also need three folders to hold the data from your containers. Here is the command to create the &lt;code&gt;/data&lt;/code&gt;, &lt;code&gt;/app&lt;/code&gt;, and &lt;code&gt;/front&lt;/code&gt; folders:&lt;/p&gt; &lt;pre&gt;$ mkdir ./data &amp;#38;&amp;#38; mkdir ./app &amp;#38;&amp;#38; mkdir ./front &lt;/pre&gt; &lt;h3&gt;Create the database container&lt;/h3&gt; &lt;p&gt;To start a Strapi instance, you will need a database to persist your data. In this example, we&amp;#8217;ll use a MySQL database server running inside a container. This way, there is no need to go through the process of installing MySQL.&lt;/p&gt; &lt;p&gt;To run the server, you can use the &lt;code&gt;docker run&lt;/code&gt; command with the &lt;code&gt;-d&lt;/code&gt; argument to run in the background. Include the following parameters:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;i&gt;&lt;code&gt;--name&lt;/code&gt; to name the container.&lt;/i&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-v&lt;/code&gt; to specify a folder to contain the data to reuse the next time you start the server.&lt;/li&gt; &lt;li&gt;&lt;code&gt;-e&lt;/code&gt; to set up the environment variables to configure the database.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The command to start the container should look like this:&lt;/p&gt; &lt;pre&gt;$ docker run --rm -d --name strapi-db -v $(pwd)/data:/var/lib/mysql:z --network=strapi -e MYSQL_DATABASE=strapi -e MYSQL_USER=strapi -e MYSQL_PASSWORD=strapi -e MYSQL_ROOT_PASSWORD=strapi-admin mysql:5.7 &lt;/pre&gt; &lt;p&gt;Note that we use the &lt;code&gt;--network&lt;/code&gt; parameter to connect the database container to the network we created earlier.&lt;/p&gt; &lt;p&gt;After executing this command, try a &lt;code&gt;docker ps&lt;/code&gt; to validate that the container has started.&lt;/p&gt; &lt;h3&gt;Create the back-end container&lt;/h3&gt; &lt;p&gt;Now that you&amp;#8217;ve configured the database, you can start your &lt;code&gt;strapi&lt;/code&gt; instance, which will run from a container. This time, you will use the &lt;code&gt;strapi/strapi&lt;/code&gt; base image. You can still use the &lt;code&gt;-d&lt;/code&gt; argument to run it in the background and &lt;code&gt;--name&lt;/code&gt; to name your container. Be sure to also add the Strapi container to the same network as the database.&lt;/p&gt; &lt;p&gt;You should also map your local &lt;code&gt;/app&lt;/code&gt; folder to &lt;code&gt;/srv/app&lt;/code&gt;:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Use the &lt;code&gt;-v&lt;/code&gt; parameter so that you can persist the files created by Strapi using a local folder on your machine.&lt;/li&gt; &lt;li&gt;Map a port on your operating system to access port 1337 inside the container. If you are using port 8080, the address to connect to the Strapi admin console will be &lt;code&gt;localhost:8080&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Configure Strapi to use the database you started in the previous step using environment variables.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Here is the command to start the Strapi back-end container:&lt;/p&gt; &lt;pre&gt;$ docker run --rm -d --name strapi-dev -p 8080:1337 -v $(pwd)/app:/srv/app:z --network=strapi -e DATABASE_CLIENT=mysql -e DATABASE_NAME=strapi -e DATABASE_HOST=strapi-db -e DATABASE_PORT=3306 -e DATABASE_USERNAME=strapi -e DATABASE_PASSWORD=strapi strapi/strapi &lt;/pre&gt; &lt;p&gt;If Strapi can&amp;#8217;t find any files in the local file system that you mapped, it will automatically create a new instance of a Strapi server. This can take a few minutes. You can use &lt;code&gt;docker logs&lt;/code&gt; to keep an eye on the application creation status:&lt;/p&gt; &lt;pre&gt;$ docker logs -f strapi-dev &lt;/pre&gt; &lt;p&gt;If you want to stop the logs in your console, enter &lt;b&gt;Ctrl-C&lt;/b&gt;.&lt;/p&gt; &lt;p&gt;Once you see a message stating that your Strapi server is started, you can go to &lt;a target="_blank" rel="nofollow" href="http://localhost:8080/admin"&gt;http://localhost:8080/admin&lt;/a&gt; to create your admin user.&lt;/p&gt; &lt;p&gt;After you&amp;#8217;ve created the admin user, go ahead and create a new content type and make it publicly available. For content to work with in the next step, create a &lt;b&gt;Content-Type&lt;/b&gt; for &lt;b&gt;Posts&lt;/b&gt;. It will have four fields: &lt;b&gt;title&lt;/b&gt;, &lt;b&gt;author&lt;/b&gt; (a relationship to &lt;b&gt;Users&lt;/b&gt;), &lt;b&gt;publish_date&lt;/b&gt;, and &lt;b&gt;content&lt;/b&gt;, as shown in Figure 1.&lt;/p&gt; &lt;div id="attachment_893687" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/Screenshot_20210408_120444.png"&gt;&lt;img aria-describedby="caption-attachment-893687" class="wp-image-893687 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/Screenshot_20210408_120444-1024x553.png" alt="The Posts content type has four fields: Title, Author, Publish_date, and Content." width="640" height="346" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/Screenshot_20210408_120444-1024x553.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/Screenshot_20210408_120444-300x162.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/Screenshot_20210408_120444-768x415.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-893687" class="wp-caption-text"&gt;Figure 1: The new content type with four fields for posts.&lt;/p&gt;&lt;/div&gt; &lt;p style="padding-left: 40px"&gt;&lt;b&gt;Note&lt;/b&gt;: See &lt;a target="_blank" rel="nofollow" href="https://www.youtube.com/watch?v=VC9X9O5OFyc"&gt;this video&lt;/a&gt; from the &lt;a target="_blank" rel="nofollow" href="https://strapi.io"&gt;Strapi&lt;/a&gt; team for a full tutorial about creating new content types.&lt;/p&gt; &lt;h3&gt;Create the front-end container&lt;/h3&gt; &lt;p&gt;Next up, you will create a front end. This user interface (UI) will consist of a simple HTML file that fetches the Strapi application programming interface (API) data and displays it on the page.&lt;/p&gt; &lt;p&gt;We&amp;#8217;ll use a Nginx server to display the content. You can start the container similarly to how you started the other two. This time, map port 80 in the container to port 8888 on your local machine and mount the &lt;code&gt;/front&lt;/code&gt; folder to map to &lt;code&gt;/usr/share/nginx/html&lt;/code&gt; inside your container. The &lt;code&gt;/front&lt;/code&gt; folder is the default folder to serve files from with Nginx:&lt;/p&gt; &lt;pre&gt;$ docker run --rm -d --name strapi-front -p 8888:80 -v $(pwd)/front:/usr/share/nginx/html:z nginx:1.17 &lt;/pre&gt; &lt;p&gt;Now, go ahead and create your front-end application. You might use a React, VueJS, or Angular application, but we&amp;#8217;ll use a simple HTML file for this demo. The file will do a &lt;code&gt;fetch&lt;/code&gt; from the Strapi API to download the data and then create the necessary elements on the page using JavaScript.&lt;/p&gt; &lt;p&gt;The HTML page will have a single &lt;code&gt;div&lt;/code&gt; where the JavaScript code appends the API&amp;#8217;s content. Create the following &lt;code&gt;index.html&lt;/code&gt; file in the &lt;code&gt;/front&lt;/code&gt; folder:&lt;/p&gt; &lt;pre&gt;&amp;#60;body&amp;#62; &amp;#60;div id="content"&amp;#62;&amp;#60;/div&amp;#62; &amp;#60;/body&amp;#62; &lt;/pre&gt; &lt;p&gt;You will need to add a &lt;code&gt;script&lt;/code&gt; tag to include a configuration file, which will make it easier to overwrite your Strapi API location later. Add the following inside the &lt;code&gt;index.html&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&amp;#60;script type="text/javascript" src="config.js"&amp;#62; &lt;/pre&gt; &lt;p&gt;The &lt;code&gt;front/config.js&lt;/code&gt; file should create a global constant with the following configuration:&lt;/p&gt; &lt;pre&gt;const config = { BASE_URL: "http://localhost:8080" } &lt;/pre&gt; &lt;p&gt;Finally, in the &lt;code&gt;index.html&lt;/code&gt; file, add another &lt;code&gt;script&lt;/code&gt; tag that contains the code to download the content and display it on the page:&lt;/p&gt; &lt;pre&gt;window.addEventListener("DOMContentLoaded", e =&amp;#62; { console.log("Loading content from Strapi"); const BASE_URL = config.BASE_URL; const BLOG_POSTS_URL = `${BASE_URL}/posts`; fetch(BLOG_POSTS_URL).then(resp =&amp;#62; resp.json()).then(posts =&amp;#62; { for(let i = 0; i &amp;#60; posts.length; i++) { let postData = posts[i]; let post = document.createElement("div"); let title = document.createElement("h2"); title.innerText = postData.title; let author = document.createElement("h3"); author.innerText = `${postData.author.firstname} ${postData.author.lastname} -- ${postData.publish_date}`; let content = document.createElement("div"); content.innerText = postData.content; post.appendChild(title); post.appendChild(author); post.appendChild(content); document.querySelector("#content").appendChild(post); } }); }); &lt;/pre&gt; &lt;p&gt;Now that you&amp;#8217;ve created all the files go to &lt;a target="_blank" rel="nofollow" href="http://localhost:8888/"&gt;http://localhost:8888&lt;/a&gt; to see your application. You should see your fancy UI serving content from Strapi.&lt;/p&gt; &lt;h2&gt;Step 2: Set up the production environment&lt;/h2&gt; &lt;p&gt;When you are ready to deploy your application, you will need to create your own containers that contain all the necessary files and data. These containers will go live on the web.&lt;/p&gt; &lt;p&gt;For each container, you will need to create a Dockerfile. You will use the Dockerfiles to create your containers with the actual content. Then, you&amp;#8217;ll deploy the containers to Kubernetes or OpenShift.&lt;/p&gt; &lt;h3&gt;Create the database container&lt;/h3&gt; &lt;p&gt;There is a good chance that you already have a database in production, and you probably won&amp;#8217;t want to overwrite its contents. For this reason, you will use the same default MySQL image that you used in development for the production database. If you want to import the SQL content later, you can use Docker to run a &lt;code&gt;mysqldump&lt;/code&gt; command on your database:&lt;/p&gt; &lt;pre&gt;$ docker exec strapi-db /bin/bash -c 'mysqldump strapi -ustrapi -pstrapi' | tee strapi-db.sql &lt;/pre&gt; &lt;p&gt;This file will be imported into the production database later if it&amp;#8217;s needed.&lt;/p&gt; &lt;p style="padding-left: 40px"&gt;&lt;b&gt;Note&lt;/b&gt;: The &lt;code&gt;mysqldump&lt;/code&gt; command uses &lt;code&gt;tee&lt;/code&gt; to copy the contents to a file. If you don&amp;#8217;t have the &lt;code&gt;tee&lt;/code&gt; command, you can copy the &lt;code&gt;docker&lt;/code&gt; command&amp;#8217;s output into a file named &lt;code&gt;strapi-db.sql&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;Create the back-end container&lt;/h3&gt; &lt;p&gt;Next, you will create a &lt;code&gt;Dockefile.back&lt;/code&gt; to build your container for the back end.&lt;/p&gt; &lt;p&gt;Start from the &lt;code&gt;strapi&lt;/code&gt; base image &lt;code&gt;FROM strapi/base&lt;/code&gt;. Change the working directory to &lt;code&gt;/opt/app&lt;/code&gt; and copy all the local files into the container. Next, expose port 1337 and set all your environment variables. Don&amp;#8217;t forget to add an environment variable for &lt;code&gt;NODE_ENV=production&lt;/code&gt;. Finally, execute &lt;code&gt;yarn build&lt;/code&gt; to build all the production resources and use the &lt;code&gt;CMD&lt;/code&gt; command to start the back end once the container is started.&lt;/p&gt; &lt;p style="padding-left: 40px"&gt;&lt;b&gt;Note&lt;/b&gt;: For more about using the Strapi base image, see the &lt;a target="_blank" rel="nofollow" href="https://github.com/strapi/strapi-docker#how-to-use-strapibase"&gt;Strapi documentation on GitHub&lt;/a&gt;.&lt;/p&gt; &lt;pre&gt;FROM strapi/base WORKDIR /opt/app COPY ./app/package.json ./ COPY ./app/yarn.lock ./ RUN yarn install COPY ./app . ENV NODE_ENV production ENV DATABASE_CLIENT=mysql ENV DATABASE_NAME=strapi ENV DATABASE_HOST=strapi-db ENV DATABASE_PORT=3306 ENV DATABASE_USERNAME=strapi ENV DATABASE_PASSWORD=strapi RUN yarn build EXPOSE 1337 CMD ["yarn", "start"] &lt;/pre&gt; &lt;h3&gt;Create the front-end container&lt;/h3&gt; &lt;p&gt;You&amp;#8217;ll have to do a bit of bash scripting to use an environment variable to specify your Strapi server&amp;#8217;s URL.&lt;/p&gt; &lt;p style="padding-left: 40px"&gt;&lt;b&gt;Note&lt;/b&gt;: See my &lt;a target="_blank" rel="nofollow" href="/blog/2021/03/04/building-rootless-containers-for-javascript-front-ends/"&gt;best practices for JavaScript front-end containers&lt;/a&gt; for more about using environment variables with front-end containers.&lt;/p&gt; &lt;p&gt;First, start with the &lt;code&gt;nginx:1.17&lt;/code&gt; base image and change the working directory to &lt;code&gt;/usr/share/nginx/html&lt;/code&gt;. In there, copy all the files from your local system into the container.&lt;/p&gt; &lt;p&gt;The next step involves using &lt;code&gt;sed&lt;/code&gt; to change the &lt;code&gt;BASE_URL&lt;/code&gt; value to &lt;code&gt;$BASE_URL&lt;/code&gt;. Then, you will pipe in the result to a new file called &lt;code&gt;config.new.js&lt;/code&gt; and rename the file to &lt;code&gt;config.js&lt;/code&gt;, overwriting the original.&lt;/p&gt; &lt;p&gt;The result inside the container is a new &lt;code&gt;config.js&lt;/code&gt; file that looks like the one below. Note that the original file in your local file system is left intact:&lt;/p&gt; &lt;pre&gt;const config = { BASE_URL: "$BASE_URL" } &lt;/pre&gt; &lt;p&gt;Finally, you will need to use &lt;code&gt;envsubst&lt;/code&gt; to change the value of &lt;code&gt;$BASE_URL&lt;/code&gt; to the environment variable&amp;#8217;s actual value. Make the following updates in the &lt;code&gt;ENTRYPOINT&lt;/code&gt;, so the changes will happen when someone issues a Docker run:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Use a &lt;code&gt;cat&lt;/code&gt; command to pipe the &lt;code&gt;config.js&lt;/code&gt; file into &lt;code&gt;envsubst&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Pipe the output to &lt;code&gt;tee&lt;/code&gt; to create a new &lt;code&gt;config.new.js&lt;/code&gt; file and rename the file to overwrite the previous one.&lt;/li&gt; &lt;li&gt;Use the&lt;code&gt;nginx -g 'daemon off;'&lt;/code&gt; command to start the Nginx server: &lt;pre&gt;FROM nginx:1.17 WORKDIR /usr/share/nginx/html COPY ./front/*.* ./ RUN sed s/BASE_URL\:\ \"[a-zA-Z0-9:\/]*\"/BASE_URL\:\ \"\$BASE_URL\"/g config.js &amp;#62; config.new.js &amp;#38;&amp;#38; mv config.new.js config.js ENTRYPOINT cat config.js | envsubst | tee config.new.js &amp;#38;&amp;#38; mv config.new.js config.js &amp;#38;&amp;#38; nginx -g 'daemon off;' &lt;/pre&gt; &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Updating the entry point instead of a &lt;code&gt;RUN&lt;/code&gt; lets you specify different values for the base URL according to where the container is running.&lt;/p&gt; &lt;h3&gt;Build the containers&lt;/h3&gt; &lt;p&gt;Now that you have all your Dockerfiles ready, you can build the containers and push them to your favorite image registry. Don&amp;#8217;t forget to change the name of your images to use your username for that registry:&lt;/p&gt; &lt;pre&gt;$ docker build -t $DOCKER_USERNAME/strapi-front -f Dockerfile.front . $ docker build -t $DOCKER_USERNAME/strapi-back -f Dockerfile.back . $ docker push $DOCKER_USERNAME/strapi-front $ docker push $DOCKER_USERNAME/strapi-back &lt;/pre&gt; &lt;h2&gt;Step 3: Package and run the application&lt;/h2&gt; &lt;p&gt;Now that you have containers with all of your code and data, you are ready to deploy the containers somewhere. We&amp;#8217;ll use Docker and Docker Compose to run the application and a Kubernetes or OpenShift cluster to deploy it.&lt;/p&gt; &lt;h3&gt;Package and run the application with Docker&lt;/h3&gt; &lt;p&gt;If you want to run this application, you can start all the containers in the same way you would in production.&lt;/p&gt; &lt;p&gt;The commands to start the containers are similar to those you used in development mode, but &lt;i&gt;with&lt;/i&gt; the mounted volumes and &lt;i&gt;without&lt;/i&gt; the environment variables. We handled the source code and environment variables in the Dockerfile. Note that we add an environment variable specifying the location of the Strapi API for starting the front end:&lt;/p&gt; &lt;pre&gt;$ docker run --rm -d --name strapi-db -v $(pwd)/data:/var/lib/mysql:z --network=strapi -e MYSQL_DATABASE=strapi -e MYSQL_USER=strapi -e MYSQL_PASSWORD=strapi -e MYSQL_ROOT_PASSWORD=strapi-admin mysql:5.7 $ docker run --rm -d --name strapi -p 1337:1337 --network=strapi $DOCKER_USERNAME/strapi-back $ docker run --rm -d --name strapi-front -p 8080:80 -e BASE_URL=http://localhost:1337 $DOCKER_USERNAME/strapi-front &lt;/pre&gt; &lt;h3&gt;Package and run the application with Docker Compose&lt;/h3&gt; &lt;p&gt;If you want to share your application code and configurations with anyone else, you could provide them with a &lt;code&gt;docker-compose.yaml&lt;/code&gt; file. This tool lets you manage multiple containers at once without multiple bash commands:&lt;/p&gt; &lt;pre&gt;version: '3' services: strapi-db: image: mysql:5.7 volumes: - ./data:/var/lib/mysql networks: - strapi strapi-back: image: $DOCKER_USERNAME/strapi-back ports: - '1337:1337' networks: - strapi strapi-front: image: $DOCKER_USERNAME/strapi-front ports: - '8080:80' environment: BASE_URL: http://localhost:1337 networks: strapi: &lt;/pre&gt; &lt;h2&gt;Step 4: Deploy the application&lt;/h2&gt; &lt;p&gt;Once you&amp;#8217;ve created all of your containers, you can deploy the application into a Kubernetes or OpenShift cluster. I&amp;#8217;ll show you how to do both.&lt;/p&gt; &lt;h3&gt;Deploy the application on Kubernetes&lt;/h3&gt; &lt;p&gt;Before deploying your application in a Kubernetes cluster, you will need to use YAML files to create all the necessary assets. For more details on each of these assets, see &lt;a target="_blank" rel="nofollow" href="http://kubernetesbyexample.com/"&gt;&lt;em&gt;Kubernetes by example&lt;/em&gt;&lt;/a&gt;. To test out the deployment, you can use a smaller version of Kubernetes to run locally on your own machine. I&amp;#8217;ve used &lt;a target="_blank" rel="nofollow" href="https://kubernetes.io/docs/tutorials/hello-minikube/"&gt;Minikube&lt;/a&gt; for the following examples.&lt;/p&gt; &lt;h4&gt;Deploying the database&lt;/h4&gt; &lt;p&gt;The setup for &lt;a target="_blank" rel="nofollow" href="https://kubernetesbyexample.com/pv/"&gt;persistent volumes&lt;/a&gt; (PVs) and persistent volume claims (PVCs) varies from one cloud provider to another. For this reason, the database in this example will not persist data. For more information about how to persist data, check your cloud provider&amp;#8217;s documentation.&lt;/p&gt; &lt;p&gt;For the database, we will need to create a &lt;a target="_blank" rel="nofollow" href="https://kubernetesbyexample.com/deployments/"&gt;deployment&lt;/a&gt;. You will start by creating a YAML file that describes your deployment. You can give it a name, and in the spec, you will create a template for the pods. Each pod will have a single container, which will be the ones that you&amp;#8217;ve pushed to your registry. Here is the deployment for this example (&lt;code&gt;deploy-db.yaml&lt;/code&gt;):&lt;/p&gt; &lt;pre&gt;apiVersion: apps/v1 kind: Deployment metadata: name: strapi-db spec: selector: matchLabels: component: db template: metadata: labels: component: db spec: containers: - name: strapi-db image: mysql:5.7 env: - name: MYSQL_DATABASE value: strapi - name: MYSQL_USER value: strapi - name: MYSQL_PASSWORD value: strapi - name: MYSQL_ROOT_PASSWORD value: strapi-admin &lt;/pre&gt; &lt;p&gt;Once you have your file, you can apply it to your cluster using &lt;code&gt;kubectl&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;$ kubectl apply -f ./deploy-db.yaml &lt;/pre&gt; &lt;h4&gt;Deploying the back end&lt;/h4&gt; &lt;p&gt;Your back end needs to be able to find the pods inside the cluster, so you will need to create a &lt;a target="_blank" rel="nofollow" href="https://kubernetesbyexample.com/services/"&gt;Service&lt;/a&gt; to expose each pod. We are using the defaults here, so you can use &lt;code&gt;kubectl&lt;/code&gt; to create this service:&lt;/p&gt; &lt;pre&gt;$ kubectl expose deployment strapi-db --port 3306 &lt;/pre&gt; &lt;p&gt;If you want to import data from your development environment SQL, you can run the following commands:&lt;/p&gt; &lt;pre&gt;$ kubectl cp ./strapi-db.sql $(kubectl get pod -l component=db | awk 'NR&amp;#62;1 {print $1}'):/tmp/strapi-db.sql $ kubectl exec -t $(kubectl get pod -l component=db | awk 'NR&amp;#62;1 {print $1}') -- /bin/bash -c 'mysql strapi -ustrapi -pstrapi &amp;#60; /tmp/strapi-db.sql' &lt;/pre&gt; &lt;p&gt;These commands copy the SQL file to the pods, then run a MySQL command to run it in the database.&lt;/p&gt; &lt;p&gt;You can also create your deployments for the back- and front-end portions of your application. The Strapi back end (&lt;code&gt;deploy-back.yaml&lt;/code&gt;) is the same as the database deployment, apart from the name, label, and container image:&lt;/p&gt; &lt;pre&gt;apiVersion: apps/v1 kind: Deployment metadata: name: strapi-back spec: selector: matchLabels: app: strapi component: back template: metadata: labels: app: strapi component: back spec: containers: - name: strapi-back image: joellord/strapi-back &lt;/pre&gt; &lt;h4&gt;Deploying the front end&lt;/h4&gt; &lt;p&gt;The front end (&lt;code&gt;deploy-front.yaml&lt;/code&gt;) uses a similar structure to the back end, but you also need to set the environment variable for the back end&amp;#8217;s &lt;code&gt;BASE_URL&lt;/code&gt;. For now, just set that variable&amp;#8217;s value to &lt;code&gt;/api&lt;/code&gt;. You also need to expose the container to port 80 so that it will be available to the outside world eventually:&lt;/p&gt; &lt;pre&gt;apiVersion: apps/v1 kind: Deployment metadata: name: strapi-front spec: selector: matchLabels: component: front template: metadata: labels: component: front spec: containers: - name: front image: joellord/strapi-front ports: - containerPort: 80 env: - name: BASE_URL value: /api &lt;/pre&gt; &lt;h4&gt;Create and expose the application services in your cluster&lt;/h4&gt; &lt;p&gt;Now that you&amp;#8217;ve created your deployment files, you can apply them to your cluster and create the services for each one:&lt;/p&gt; &lt;pre&gt;$ kubectl apply -f ./deploy-back.yaml $ kubectl apply -f ./deploy-front.yaml $ kubectl expose deployment strapi-back --port 1337 $ kubectl expose deployment strapi-front --port 80 &lt;/pre&gt; &lt;p&gt;Everything is now running inside your cluster. You only need to expose the front- and back-end services to the outside world. For this, you will use an &lt;a target="_blank" rel="nofollow" href="https://kubernetes.io/docs/concepts/services-networking/ingress/"&gt;ingress&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Here, you will create an ingress that exposes the front end as the default service. Any incoming request to your cluster then goes to the front end by default. You will also add a rule that redirects any traffic sent to  &lt;code&gt;/api/*&lt;/code&gt; to the back-end service. The request will be rewritten when it&amp;#8217;s sent to that service to remove the &lt;code&gt;/api&lt;/code&gt; part of the URL. We&amp;#8217;ll add a Nginx annotation in the metadata to effect this change. Here is the &lt;code&gt;ingress.yaml&lt;/code&gt; file:&lt;/p&gt; &lt;pre&gt;apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: main-ingress annotations: nginx.ingress.kubernetes.io/rewrite-target: /$2 spec: rules: - http: paths: - path: /api(/|$)(.*) pathType: Prefix back end: service: name: strapi-back port: number: 1337 - path: /()(.*) pathType: Prefix backend: service: name: strapi-front port: number: 80 &lt;/pre&gt; &lt;p&gt;Go ahead and apply this file to your cluster. You might need to enable the following add-on if you are using Minikube and have never used an ingress before:&lt;/p&gt; &lt;pre&gt;# For minikube users $ minikube addons enable ingress $ kubectl apply -f ./ingress.yaml &lt;/pre&gt; &lt;p&gt;You now have everything needed to run your Strapi application in a Kubernetes cluster. Point your browser to the cluster URL, and you should see the full application running in your cluster. If you&amp;#8217;re using Minikube, you can use the command &lt;code&gt;minikube ip&lt;/code&gt; to get your cluster&amp;#8217;s address.&lt;/p&gt; &lt;h3&gt;Deploy the application on OpenShift&lt;/h3&gt; &lt;p&gt;Deploying the application on OpenShift can be even easier than deploying in a Kubernetes cluster.&lt;/p&gt; &lt;p&gt;In this case, you can test out your deployment with the &lt;a target="_blank" rel="nofollow" href="/developer-sandbox"&gt;Developer Sandbox&lt;/a&gt;, which gives you access to an OpenShift cluster for free for 14 days.&lt;/p&gt; &lt;h4&gt;Create the deployment from an image&lt;/h4&gt; &lt;p&gt;The command-line interface (CLI) tool that you use to manage your cluster (&lt;code&gt;oc&lt;/code&gt;) can create a deployment directly from an image. To deploy your application, enter:&lt;/p&gt; &lt;pre&gt;$ oc new-app mysql:5.7 MYSQL_USER=strapi MYSQL_PASSWORD=strapi MYSQL_DATABASE=strapi -l component=db --name strapi-db $ oc new-app joellord/strapi-back-openshift --name strapi-back $ oc new-app joellord/strapi-front-openshift --name strapi-front &lt;/pre&gt; &lt;p&gt;&lt;b&gt;Note&lt;/b&gt;: Images on OpenShift need to be run as a non-root user. See my &lt;a target="_blank" rel="nofollow" href="https://github.com/joellord/frontend-containers"&gt;guide to front-end best practices&lt;/a&gt; for more about non-root images. The Dockerfiles used for this project can be found in the &lt;a target="_blank" rel="nofollow" href="https://github.com/joellord/strapi"&gt;Git repository for this article&lt;/a&gt; under &lt;code&gt;Dockerfile.rootless.back&lt;/code&gt; and &lt;code&gt;Dockerfile.rootless.front&lt;/code&gt;.&lt;/p&gt; &lt;div&gt; &lt;div&gt;Seed your database with the data that you exported earlier. This data should be in your current working directory and have the name &lt;code&gt;strapi-db.sql&lt;/code&gt;.&lt;/div&gt; &lt;pre&gt;$ oc exec -it $(oc get pods -l component=db | awk 'NR&amp;#62;1 {print $1}') -c strapi-db -- bash -c 'mysql -ustrapi -pstrapi strapi' &amp;#60; ./strapi-db.sql&lt;/pre&gt; &lt;/div&gt; &lt;h4&gt;Expose the application&lt;/h4&gt; &lt;p&gt;Next, you&amp;#8217;ll want to expose the application to the outside world. OpenShift has a neat object for this purpose, &lt;code&gt;Route&lt;/code&gt;, which you can use from the OpenShift CLI. Use the &lt;code&gt;oc expose&lt;/code&gt; command to expose the back- and front-end to the outside world:&lt;/p&gt; &lt;pre&gt;$ oc expose service strapi-back $ oc expose service strapi-front --port=8080 &lt;/pre&gt; &lt;p&gt;Now that your back end is exposed, you will need to set your front-end environment variable to the back-end route. Start by getting the public route for the Strapi API:&lt;/p&gt; &lt;pre&gt;$ oc get routes &lt;/pre&gt; &lt;p&gt;You should see all the routes that you&amp;#8217;ve created so far. You can store the back-end route in a variable and then set it as an environment variable using &lt;code&gt;oc set env&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;$ export BACKEND_ROUTE=$(oc get routes | grep strapi-back | awk '{print $2}') $ oc set env deployment/strapi-front BASE_URL=http://$BACKEND_ROUTE &lt;/pre&gt; &lt;p&gt;You can now access your Strapi application using the route for the &lt;code&gt;strapi-front&lt;/code&gt; service.&lt;/p&gt; &lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;When you are ready to put your Strapi application in production, the first step will be to containerize your whole setup. Once you have that done, you can deploy those containers in Kubernetes. You&amp;#8217;ve also seen how easy it is to deploy a Strapi application to OpenShift.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F09%2Fcontainerize-and-deploy-strapi-applications-on-kubernetes-and-red-hat-openshift%2F&amp;#38;linkname=Containerize%20and%20deploy%20Strapi%20applications%20on%20Kubernetes%20and%20Red%20Hat%20OpenShift" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F09%2Fcontainerize-and-deploy-strapi-applications-on-kubernetes-and-red-hat-openshift%2F&amp;#38;linkname=Containerize%20and%20deploy%20Strapi%20applications%20on%20Kubernetes%20and%20Red%20Hat%20OpenShift" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F09%2Fcontainerize-and-deploy-strapi-applications-on-kubernetes-and-red-hat-openshift%2F&amp;#38;linkname=Containerize%20and%20deploy%20Strapi%20applications%20on%20Kubernetes%20and%20Red%20Hat%20OpenShift" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F09%2Fcontainerize-and-deploy-strapi-applications-on-kubernetes-and-red-hat-openshift%2F&amp;#38;linkname=Containerize%20and%20deploy%20Strapi%20applications%20on%20Kubernetes%20and%20Red%20Hat%20OpenShift" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F09%2Fcontainerize-and-deploy-strapi-applications-on-kubernetes-and-red-hat-openshift%2F&amp;#38;linkname=Containerize%20and%20deploy%20Strapi%20applications%20on%20Kubernetes%20and%20Red%20Hat%20OpenShift" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F09%2Fcontainerize-and-deploy-strapi-applications-on-kubernetes-and-red-hat-openshift%2F&amp;#38;linkname=Containerize%20and%20deploy%20Strapi%20applications%20on%20Kubernetes%20and%20Red%20Hat%20OpenShift" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F09%2Fcontainerize-and-deploy-strapi-applications-on-kubernetes-and-red-hat-openshift%2F&amp;#38;linkname=Containerize%20and%20deploy%20Strapi%20applications%20on%20Kubernetes%20and%20Red%20Hat%20OpenShift" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F09%2Fcontainerize-and-deploy-strapi-applications-on-kubernetes-and-red-hat-openshift%2F&amp;#038;title=Containerize%20and%20deploy%20Strapi%20applications%20on%20Kubernetes%20and%20Red%20Hat%20OpenShift" data-a2a-url="https://developers.redhat.com/blog/2021/04/09/containerize-and-deploy-strapi-applications-on-kubernetes-and-red-hat-openshift/" data-a2a-title="Containerize and deploy Strapi applications on Kubernetes and Red Hat OpenShift"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/09/containerize-and-deploy-strapi-applications-on-kubernetes-and-red-hat-openshift/"&gt;Containerize and deploy Strapi applications on Kubernetes and Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/LW4jocGRXEk" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Strapi is the leading open-source headless content management system (CMS). It’s 100% JavaScript, fully customizable, and takes a developer-first approach. Strapi provides you with an interface to create and manage all the resources for your website. You can then build a front end to connect to your Strapi API with your favorite tools and frameworks. [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/09/containerize-and-deploy-strapi-applications-on-kubernetes-and-red-hat-openshift/"&gt;Containerize and deploy Strapi applications on Kubernetes and Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/04/09/containerize-and-deploy-strapi-applications-on-kubernetes-and-red-hat-openshift/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">874347</post-id><dc:creator>Joel Lord</dc:creator><dc:date>2021-04-09T07:00:16Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/04/09/containerize-and-deploy-strapi-applications-on-kubernetes-and-red-hat-openshift/</feedburner:origLink></entry><entry><title>What’s happening in the Node.js community</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/QDm6YjHifkE/" /><category term="JavaScript" /><category term="Node.js" /><category term="Open source" /><category term="Node.js Next 10 Survey" /><category term="Node.js package maintenance" /><category term="Node.js runtime features" /><author><name>Bethany Griggs</name></author><id>https://developers.redhat.com/blog/?p=879727</id><updated>2021-04-08T07:00:27Z</updated><published>2021-04-08T07:00:27Z</published><content type="html">&lt;p&gt;Curious about what’s going on in the &lt;a target="_blank" rel="nofollow" href="/topics/nodejs/"&gt;Node.js&lt;/a&gt; community?&lt;/p&gt; &lt;p&gt;Node.js 16 will be released in April 2021 and promoted to long-term support in October 2021. We’re also rapidly approaching the end-of-life date for Node.js 10. After April 2021, there will be no further patches or security fixes made available for the Node.js 10 release line. If you haven’t already, you should plan to upgrade to Node.js 12 or Node.js 14 as soon as possible. See the &lt;a href="https://github.com/nodejs/release#release-schedule"&gt;Node.js release schedule&lt;/a&gt; in Figure 1.&lt;/p&gt; &lt;p&gt;&lt;img class="wp-image-879737 size-large aligncenter" src="https://developers.redhat.com/blog/wp-content/uploads/2021/03/Screenshot-2021-03-09-at-11.23.48-e1615289135331-1024x532.png" alt="Node.js release timeline spanning October 2020 to January 2023." width="640" height="333" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/03/Screenshot-2021-03-09-at-11.23.48-e1615289135331-1024x532.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/03/Screenshot-2021-03-09-at-11.23.48-e1615289135331-300x156.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/03/Screenshot-2021-03-09-at-11.23.48-e1615289135331-768x399.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;br /&gt; Figure 1: An overview of the Node.js release timeline.&lt;/p&gt; &lt;h2&gt;New features in Node.js 15&lt;/h2&gt; &lt;p&gt;The “current” release line, Node.js 15, picks up the new features that are contributed to the runtime first. Features now available in Node.js 15 include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/nodejs/node/pull/36729"&gt;&lt;code&gt;crypto.randomUUID()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/nodejs/node/pull/37179"&gt;&lt;code&gt;fsPromises.watch()&lt;/code&gt;&lt;/a&gt;, an alternative version of &lt;code&gt;fs.watch()&lt;/code&gt; that returns an &lt;code&gt;AsyncIterator&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/nodejs/node/pull/37155"&gt;New &lt;code&gt;perf_hooks.createHistogram()&lt;/code&gt; API&lt;/a&gt; for creating histogram instances that allow user recording&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/nodejs/node/pull/37117"&gt;npm 7.5&lt;/a&gt;, including the new &lt;code&gt;npm diff&lt;/code&gt; command&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/nodejs/node/pull/37362"&gt;Support for source maps&lt;/a&gt; has graduated from experimental status to stable (proposed by Benjamin Coe)&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Hot topics in the Node.js community&lt;/h2&gt; &lt;p&gt;The following issues have sparked discussion in the Node.js community recently:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/nodejs/node/issues/37309"&gt;Work progressing toward producing native Node.js binaries for Apple Silicon&lt;/a&gt;, to be distributed as a single “fat” (multi-architecture) binary for macOS&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/nodejs/node/issues/19393#"&gt;Renewed discussion around including &lt;code&gt;fetch()&lt;/code&gt; or a &lt;code&gt;fetch()&lt;/code&gt;-like API in Node.js core&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/nodejs/node/issues/35286#"&gt;A proposal to promote the experimental APIs &lt;code&gt;AsyncResource&lt;/code&gt; and &lt;code&gt;AsyncLocalStorage&lt;/code&gt; to stable status&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt; The Node.js package maintenance ecosystem&lt;/h2&gt; &lt;p&gt;The Node.js Package Maintenance Working Group aims to help maintainers in a number of ways. Two active efforts are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Encouraging the publishing of package support information&lt;/strong&gt;: Publishing package support information helps maintainers set expectations in terms of supported Node.js versions, general support availability, and the backing behind a given package. The Working Group has defined the recommended metadata in &lt;a target="_blank" rel="nofollow" href="https://github.com/nodejs/package-maintenance/blob/main/docs/PACKAGE-SUPPORT.md"&gt;&lt;code&gt;PACKAGE-SUPPORT.md&lt;/code&gt;&lt;/a&gt;. New this month: The addition of a &lt;code&gt;create&lt;/code&gt; command to the &lt;a target="_blank" rel="nofollow" href="https://github.com/pkgjs/support"&gt;support&lt;/a&gt; tool, which makes it easier for maintainers to add this metadata to their packages. &lt;code&gt;npx @pkgjs/support create&lt;/code&gt; will guide you through adding the recommended metadata to your package. The &lt;a target="_blank" rel="nofollow" href="https://github.com/nodeshift/nodeshift"&gt;Nodeshift project&lt;/a&gt; recently added package support information to our modules. You can read more about our experience in &lt;a target="_blank" rel="nofollow" href="/blog/2021/02/10/add-standardized-support-information-to-your-node-js-modules"&gt;this article&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;The wiby testing tool&lt;/strong&gt;: The Working Group continues to develop wiby (“Will I break you?”). Still in early development, this tool helps package maintainers test whether changes in their packages break other packages that depend on them. If you’re interested in module testing or you’re a module maintainer wanting to test the impact of your changes on your downstream dependents, you can watch a &lt;a target="_blank" rel="nofollow" href="https://youtu.be/m4SMPUshtzY?t=47"&gt;demo&lt;/a&gt; and/or follow the progress in the &lt;a target="_blank" rel="nofollow" href="https://github.com/pkgjs/wiby"&gt;GitHub repository&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;The next 10 years of Node.js&lt;/h2&gt; &lt;p&gt;The Node.js project is documenting what we think is important to make the next 10 years of Node.js as successful as the first 10 years. The &lt;a target="_blank" rel="nofollow" href="https://github.com/nodejs/next-10"&gt;Next-10&lt;/a&gt; effort is focused on defining the project’s technical values and constituencies to set the foundation for future discussions. We’ve had many conversations and documented our initial thoughts, but now we need your help. The project has launched a survey to confirm that these values and constituencies align with our users&amp;#8217; needs. You can help guide the future of Node.js by taking part in the &lt;a target="_blank" rel="nofollow" href="https://www.surveymonkey.com/r/8PFGKV5"&gt;survey&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Upcoming virtual events&lt;/h2&gt; &lt;p&gt;Although we’ve been unable to meet in person over the past year, the Node.js community is still getting together at virtual events. Upcoming events include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://openjsf.org/openjs-world-2021/"&gt;OpenJS World&lt;/a&gt; (June 2, 2021)&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://www.nodeconfremote.com/"&gt;NodeConf Remote&lt;/a&gt; (October 18-21, 2021)&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Stay up to date on Node.js&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="/topics/nodejs"&gt;Node.js on Red Hat Developer&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://developer.ibm.com/languages/node-js/"&gt;Node.js on IBM Developer&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://nodejs.org/en/blog/"&gt;The Node.js project blog&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F08%2Fwhats-happening-in-the-node-js-community%2F&amp;#38;linkname=What%E2%80%99s%20happening%20in%20the%20Node.js%20community" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F08%2Fwhats-happening-in-the-node-js-community%2F&amp;#38;linkname=What%E2%80%99s%20happening%20in%20the%20Node.js%20community" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F08%2Fwhats-happening-in-the-node-js-community%2F&amp;#38;linkname=What%E2%80%99s%20happening%20in%20the%20Node.js%20community" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F08%2Fwhats-happening-in-the-node-js-community%2F&amp;#38;linkname=What%E2%80%99s%20happening%20in%20the%20Node.js%20community" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F08%2Fwhats-happening-in-the-node-js-community%2F&amp;#38;linkname=What%E2%80%99s%20happening%20in%20the%20Node.js%20community" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F08%2Fwhats-happening-in-the-node-js-community%2F&amp;#38;linkname=What%E2%80%99s%20happening%20in%20the%20Node.js%20community" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F08%2Fwhats-happening-in-the-node-js-community%2F&amp;#38;linkname=What%E2%80%99s%20happening%20in%20the%20Node.js%20community" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F08%2Fwhats-happening-in-the-node-js-community%2F&amp;#038;title=What%E2%80%99s%20happening%20in%20the%20Node.js%20community" data-a2a-url="https://developers.redhat.com/blog/2021/04/08/whats-happening-in-the-node-js-community/" data-a2a-title="What’s happening in the Node.js community"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/08/whats-happening-in-the-node-js-community/"&gt;What&amp;#8217;s happening in the Node.js community&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/QDm6YjHifkE" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Curious about what’s going on in the Node.js community? Node.js 16 will be released in April 2021 and promoted to long-term support in October 2021. We’re also rapidly approaching the end-of-life date for Node.js 10. After April 2021, there will be no further patches or security fixes made available for the Node.js 10 release line. [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/08/whats-happening-in-the-node-js-community/"&gt;What&amp;#8217;s happening in the Node.js community&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/04/08/whats-happening-in-the-node-js-community/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">879727</post-id><dc:creator>Bethany Griggs</dc:creator><dc:date>2021-04-08T07:00:27Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/04/08/whats-happening-in-the-node-js-community/</feedburner:origLink></entry><entry><title>Build even faster Quarkus applications with fast-jar</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/l3G5vq2brYE/" /><category term="Containers" /><category term="Java" /><category term="Kubernetes" /><category term="Quarkus" /><category term="cloud native java" /><category term="fast-jar" /><category term="Java performance" /><author><name>Daniel Oh</name></author><id>https://developers.redhat.com/blog/?p=884257</id><updated>2021-04-08T07:00:05Z</updated><published>2021-04-08T07:00:05Z</published><content type="html">&lt;p&gt;&lt;a target="_blank" rel="nofollow" href="/products/quarkus/getting-started"&gt;Quarkus&lt;/a&gt; is already fast, but what if you could make &lt;a target="_blank" rel="nofollow" href="/blog/2021/02/11/enhancing-the-development-loop-with-quarkus-remote-development/"&gt;inner loop development&lt;/a&gt; with the supersonic, subatomic &lt;a target="_blank" rel="nofollow" href="/topics/enterprise-java"&gt;Java&lt;/a&gt; framework even faster? Quarkus 1.5 introduced &lt;code&gt;fast-jar&lt;/code&gt;, a new packaging format that supports faster startup times. Starting in Quarkus 1.12, this great feature became the default packaging format for Quarkus applications. This article introduces you to the &lt;code&gt;fast-jar&lt;/code&gt; format and how it works.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: The &lt;a target="_blank" rel="nofollow" href="https://www.jrebel.com/resources/java-developer-productivity-report-2021"&gt;ninth annual global Java developer productivity report&lt;/a&gt; found that more developers are implementing business applications with &lt;a target="_blank" rel="nofollow" href="/products/quarkus/getting-started"&gt;Quarkus&lt;/a&gt;. Quarkus&amp;#8217;s support for live coding with fast startup and response times lets developers focus more on business logic implementations rather than wasting time on jobs such as recompiling and redeploying code and continuously restarting the runtime environment.&lt;/p&gt; &lt;h2&gt;The custom class loader&lt;/h2&gt; &lt;p&gt;To understand &lt;code&gt;fast-jar&lt;/code&gt;&amp;#8216;s secret solution, you need to understand the purpose of the Java class loader and what it processes when a Java application starts up. The Java class loader dynamically loads Java classes into the Java Virtual Machine (JVM) in a Java Runtime Environment (JRE). The Java class loader handles these functions so that the Java runtime doesn&amp;#8217;t need to know where the files and file systems are. Unfortunately, the class loader loads slower for Java applications with more dependencies. The reason is that the class loader typically takes the O(n) Big O notation on the number of Java application dependencies.&lt;/p&gt; &lt;p&gt;Quarkus&amp;#8217;s &lt;code&gt;fast-jar&lt;/code&gt; format solves this problem! When you create an application using the &lt;code&gt;fast-jar&lt;/code&gt; format, Quarkus uses a custom &lt;code&gt;ClassLoader&lt;/code&gt; that already knows the entire classpath when the application is built. The &lt;code&gt;ClassLoader&lt;/code&gt; indexes the location of classes and resources that are written at build time, and the location is read at startup time.&lt;/p&gt; &lt;p&gt;By following the next steps, you can learn for yourself the differences between the legacy JAR format and the new &lt;code&gt;fast-jar&lt;/code&gt; format.&lt;/p&gt; &lt;h2&gt;Step 1: Create two Quarkus projects with multiple extensions&lt;/h2&gt; &lt;p&gt;First, use a Maven plugin to scaffold a new project based on Quarkus 1.11.6.Final, which uses the legacy JAR packaging format:&lt;/p&gt; &lt;pre&gt;$ mvn io.quarkus:quarkus-maven-plugin:1.11.6.Final:create \     -DprojectGroupId=org.acme \    -DprojectArtifactId=getting-legacyjar-started \    -DclassName="org.acme.getting.started.GreetingResource" \    -Dextensions="infinispan-client,rest-client,openshift, resteasy-jackson" \    -Dpath="/hello" &lt;/pre&gt; &lt;p&gt;This command generates a &lt;code&gt;getting-legacyjar-started&lt;/code&gt; directory that pulls down &lt;code&gt;infinispan-client&lt;/code&gt;, &lt;code&gt;rest-client&lt;/code&gt;, &lt;code&gt;openshift&lt;/code&gt;, and &lt;code&gt;resteasy-jackson&lt;/code&gt; extensions into the new Quarkus project.&lt;/p&gt; &lt;p&gt;Next, create another project based on Quarkus 1.12.2.Final, with the new &lt;code&gt;fast-jar&lt;/code&gt; format:&lt;/p&gt; &lt;pre&gt;$ mvn io.quarkus:quarkus-maven-plugin:1.12.2.Final:create \    -DprojectGroupId=org.acme \    -DprojectArtifactId=getting-fastjar-started \   -DclassName="org.acme.getting.started.GreetingResource" \    -Dextensions="infinispan-client,rest-client,openshift, resteasy-jackson" \    -Dpath="/hello"&lt;/pre&gt; &lt;p&gt;This command generates a &lt;code&gt;getting-fastjar-started&lt;/code&gt; directory that includes the same extensions, but uses the &lt;code&gt;fast-jar&lt;/code&gt; packaging format.&lt;/p&gt; &lt;h2&gt;Step 2: Package the applications to compare formats&lt;/h2&gt; &lt;p&gt;Next, we&amp;#8217;ll package the applications to compare how differently Quarkus generates classes and resources using the legacy and &lt;code&gt;fast-jar&lt;/code&gt; packaging formats. Package the legacy JAR application first, using the following Maven command:&lt;/p&gt; &lt;pre&gt;$ mvn package -f getting-legacyjar-started&lt;/pre&gt; &lt;p&gt;The output should end with &lt;code&gt;BUILD SUCCESS&lt;/code&gt;. Then, the runnable JAR will be packaged directly in the target directory where other resources such as &lt;code&gt;lib&lt;/code&gt; and &lt;code&gt;classes&lt;/code&gt; are also created:&lt;/p&gt; &lt;pre&gt;$ ls -al getting-legacyjar-started/target             ... drwxr-xr-x   5 danieloh  staff     160 Mar 15 00:31 classes drwxr-xr-x  67 danieloh  staff    2144 Mar 15 08:35 lib -rw-r--r--   1 danieloh  staff  249897 Mar 15 08:35 getting-legacyjar-started-1.0.0-SNAPSHOT-runner.jar ... &lt;/pre&gt; &lt;p&gt;Now, package the &lt;code&gt;fast-jar&lt;/code&gt; application:&lt;/p&gt; &lt;pre&gt;$ mvn package -f getting-fastjar-started&lt;/pre&gt; &lt;p&gt;Once the build completes, you will find a new self-contained &lt;code&gt;quarkus-app&lt;/code&gt; folder in the target directory:&lt;/p&gt; &lt;pre&gt;$ ls -al getting-fastjar-started/target/quarkus-app         ... drwxr-xr-x  3 danieloh  staff   96 Mar 15 14:25 app drwxr-xr-x  4 danieloh  staff  128 Mar 15 14:25 lib drwxr-xr-x  4 danieloh  staff  128 Mar 15 14:25 quarkus -rw-r--r--  1 danieloh  staff  621 Mar 15 14:26 quarkus-run.jar ...&lt;/pre&gt; &lt;h2&gt;Step 3: Compare the application startup times&lt;/h2&gt; &lt;p&gt;Now, let’s run both applications with the packaged JAR file to see how quickly each one starts. Run the &lt;code&gt;legacy-jar&lt;/code&gt; application first:&lt;/p&gt; &lt;pre&gt;$ java -jar getting-legacyjar-started/target/getting-legacyjar-started-1.0.0-SNAPSHOT-runner.jar&lt;/pre&gt; &lt;p&gt;Once the application starts, you will see 1.276 seconds as the boot time, as shown below (the elapsed time could be a bit different depending on your environment):&lt;/p&gt; &lt;pre&gt;INFO  [io.quarkus] (main) getting-legacyjar-started 1.0.0-SNAPSHOT on JVM (powered by Quarkus 1.11.6.Final) started in 1.276s. Listening on: http://0.0.0.0:8080 &lt;/pre&gt; &lt;p&gt;To do a quick sanity test, you can access the RESTful API using a &lt;code&gt;curl&lt;/code&gt; command. Then, you will see the following output:&lt;/p&gt; &lt;pre&gt;$ curl &lt;a target="_blank" rel="nofollow" href="http://localhost:8080/hello"&gt;http://localhost:8080/hello&lt;/a&gt; Hello RESTEasy &lt;/pre&gt; &lt;p&gt;Stop the development mode by pressing &lt;b&gt;CTRL + C&lt;/b&gt; on your keyboard. Then, run the &lt;code&gt;fast-jar&lt;/code&gt; application:&lt;/p&gt; &lt;pre&gt;$ java -jar getting-fastjar-started/target/quarkus-app/quarkus-run.jar &lt;/pre&gt; &lt;p&gt;Once the application starts, you will see 0.909 seconds as the boot time, as shown below (the elapsed time could be a bit different depending on your environment):&lt;/p&gt; &lt;pre&gt;INFO  [io.quarkus] (main) getting-fastjar-started 1.0.0-SNAPSHOT on JVM (powered by Quarkus 1.12.2.Final) started in 0.909s. Listening on: http://0.0.0.0:8080 &lt;/pre&gt; &lt;p&gt;The new &lt;code&gt;fast-jar&lt;/code&gt; custom &lt;code&gt;ClassLoader&lt;/code&gt; delivers a startup time that is 360 milliseconds faster than the legacy JAR application. When you access the endpoint (&lt;code&gt; /hello&lt;/code&gt;), you will have the same output (&lt;code&gt;Hello RESTEasy&lt;/code&gt;) as the legacy JAR application.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;fast-jar&lt;/code&gt; format allows the default &lt;code&gt;ClassLoader&lt;/code&gt; to keep a minimum number of JARs open for fitting in a container-layering architecture. It also doesn’t need to look up the entire classpath for missing resources in known directories such as &lt;code&gt;META-INF/services&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In this article, you learned why applications packaged with &lt;code&gt;fast-jar&lt;/code&gt; are faster than those packaged with Quarkus&amp;#8217;s legacy JAR format. We also did a quick exercise so you could compare the startup times for yourself.&lt;/p&gt; &lt;p&gt;While we didn&amp;#8217;t explore this option, you might have almost the same startup time if you run both applications in development mode because development mode doesn’t use a JAR file for packaging. This enhancement is intended for a production environment.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;fast-jar&lt;/code&gt; format is useful for applications with many extensions and dependencies, and the advantages are even greater for applications deployed to a &lt;a target="_blank" rel="nofollow" href="/topics/containers"&gt;container&lt;/a&gt; environment like &lt;a target="_blank" rel="nofollow" href="/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;. Visit the Quarkus landing page to &lt;a target="_blank" rel="nofollow" href="/products/quarkus/getting-started"&gt;get started with your next Quarkus journey&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F08%2Fbuild-even-faster-quarkus-applications-with-fast-jar%2F&amp;#38;linkname=Build%20even%20faster%20Quarkus%20applications%20with%20fast-jar" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F08%2Fbuild-even-faster-quarkus-applications-with-fast-jar%2F&amp;#38;linkname=Build%20even%20faster%20Quarkus%20applications%20with%20fast-jar" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F08%2Fbuild-even-faster-quarkus-applications-with-fast-jar%2F&amp;#38;linkname=Build%20even%20faster%20Quarkus%20applications%20with%20fast-jar" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F08%2Fbuild-even-faster-quarkus-applications-with-fast-jar%2F&amp;#38;linkname=Build%20even%20faster%20Quarkus%20applications%20with%20fast-jar" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F08%2Fbuild-even-faster-quarkus-applications-with-fast-jar%2F&amp;#38;linkname=Build%20even%20faster%20Quarkus%20applications%20with%20fast-jar" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F08%2Fbuild-even-faster-quarkus-applications-with-fast-jar%2F&amp;#38;linkname=Build%20even%20faster%20Quarkus%20applications%20with%20fast-jar" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F08%2Fbuild-even-faster-quarkus-applications-with-fast-jar%2F&amp;#38;linkname=Build%20even%20faster%20Quarkus%20applications%20with%20fast-jar" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F08%2Fbuild-even-faster-quarkus-applications-with-fast-jar%2F&amp;#038;title=Build%20even%20faster%20Quarkus%20applications%20with%20fast-jar" data-a2a-url="https://developers.redhat.com/blog/2021/04/08/build-even-faster-quarkus-applications-with-fast-jar/" data-a2a-title="Build even faster Quarkus applications with fast-jar"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/08/build-even-faster-quarkus-applications-with-fast-jar/"&gt;Build even faster Quarkus applications with fast-jar&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/l3G5vq2brYE" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Quarkus is already fast, but what if you could make inner loop development with the supersonic, subatomic Java framework even faster? Quarkus 1.5 introduced fast-jar, a new packaging format that supports faster startup times. Starting in Quarkus 1.12, this great feature became the default packaging format for Quarkus applications. This article introduces you to the [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/08/build-even-faster-quarkus-applications-with-fast-jar/"&gt;Build even faster Quarkus applications with fast-jar&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/04/08/build-even-faster-quarkus-applications-with-fast-jar/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">884257</post-id><dc:creator>Daniel Oh</dc:creator><dc:date>2021-04-08T07:00:05Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/04/08/build-even-faster-quarkus-applications-with-fast-jar/</feedburner:origLink></entry><entry><title type="html">Headless eCommerce - Common architectural elements</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/1vfsy29GmIk/headless-ecommerce-common-architectural-elements.html" /><author><name>Eric D. Schabell</name></author><id>http://feedproxy.google.com/~r/schabell/jboss/~3/YHEbyyin6ig/headless-ecommerce-common-architectural-elements.html</id><updated>2021-04-08T05:00:00Z</updated><content type="html">Part 2 - Common architectural elements  In our  from this series we introduced a use case around headless e-commerce for retail stores. The process was laid out how we've approached the use case and how portfolio solutions are the base for researching a generic architectural blueprint.  The only thing left to cover was the order in which you'll be led through the blueprint details. This article starts the real journey at the very top, with a generic architecture from which we'll discuss the common architectural elements one by one. This will start our journey into the logical elements that make up the headless e-commerce architecture blueprint. BLUEPRINTS REVIEW As mentioned before, the architectural details covered here are base on real solutions using open source technologies. The example scenario presented here is a generic common blueprint that was uncovered researching those solutions. It's our intent to provide a blueprint that provides guidance and not deep technical details. This section covers the visual representations as presented, but it's expected that they'll be evolving based on future research. There are many ways to represent each element in this architectural blueprint, but we've chosen a format that we hope makes it easy to absorb. Feel free to post comments at the bottom of this post, or  with your feedback. Now let's take a look at the details in this blueprint and outline the solution. FROM SPECIFIC TO GENERIC Before diving in to the common elements, it might be nice to understand that this is not a catch all for every possible supply chain integration solution. It's a collection of identified elements that we've uncovered in multiple customer implementations. These elements presented here are then the generic common architectural elements that we've identified and collected in to the generic architectural blueprint.  It's our intent to provide a blueprint for guidance and not deep technical details. You're smart enough to figure out wiring integration points in your own architectures. You're capable of slotting in the technologies and components you've committed to in the past where applicable.  It's our job here to describe the architectural blueprint generic components and outline a few specific cases with visual diagrams so that you're able to make the right decisions from the start of your own projects. Another challenge has been how to visually represent the architectural blueprint. There are many ways to represent each element, but we've chosen some icons, text and colours that we hope are going to make it all easy to absorb.  Now let's take a quick tour of the generic architecture and outline the common elements uncovered in my research. DEVELOPER As you notice from the beginning, this logical diagram starts with a focus on cloud native development and the developer. For those that have looked at already, you'll notice the developer is central to delivering the components used in a headless e-commerce solution. For this blueprint the researched customers provided, as you could image, a diverse set of developer elements to choose from. We've chosen to group some and selected the elements shown in the image. The developer IDE is pretty universal, the tooling that the developer is coding in. Some form of source code management repository is used, but all research pointed to a Git-based repository. The remaining elements encompass as selection of the enterprise frameworks encountered, but are not by any means definitive. We captured integration based on Camel and Fuse, and often some collection of Java runtimes. While not illustrated as a distinct component, some form of dependency management was employed. In all researched cases it was an Apache Maven repository, but we've chosen to leave them out of this logical overview for the reasons of simplicity. CONTAINER PLATFORM CI / CD A container platform hosting the continuous integration (CI) and continuous development (CD) tooling is the main element in this group. The CI/CD platform can be any number of available tools, but as a concrete example, many implementations are using Jenkins tooling. Here you again see the SCM repertory as an element just like you saw in the previous developer section. This represents the connection between developer and collecting project artefacts for use in the container CI/CD platform for testing, tagging, and rolling out to various infrastructure environments in a retail organisation. PRESENTATION TIER This tier is used to collect the elements used for front end presentation for the headless e-commerce suite. This can be any number of applications used by customers to interact with the e-commerce platform, but also third parties allowed to interact with the platform.  All of these applications can be found in the generic element web applications, with a secondary element called frontend microservices that represent integration points for applications into the headless e-commerce platform. CONTAINER PLATFORM The bulk of the headless e-commerce platform can be found here in the container platform where a collection of services and communication tools are provided independent elements of deployment that support a cohesive whole. A core element of any integration platform is to provide some form of messaging to ensure that both communication and transformation of that communication is possible across the headless e-commerce platform.  Both integration microservices and integration data microservices are elements that consistently provide access to backend organisational systems, data sources, and other aspects of the retail organisation such as real-time stock control solutions or the retail data framework. In other articles, we'll cover these two architecture blueprints and you can search for them on this site for more details. To support customer interaction throughout the headless e-commerce platform there are collections of microservices, each focusing on one aspect of the customer interaction.  These are very generic descriptions as each retail organisation can determine what they consider core services. The first group is referred to as customer brand adapter microservices that ensure specific focus on creating a brand connection with the customer on your platform.  Another set of services are called the customer composite microservices that focus on coarser grained interactions with customers on their shopping journey in your online store. The basic set of services are called the customer core microservices and provide the basic interactions with customers for all parts of the e-commerce platform.  A final element is a collection of customer anti-corruption microservices that is a grouping related to the processes around payments for customers that might need access to processes around anti-money laundering or other fraud related detection mechanisms. There are often legal aspects to your specific country that effects what you need to comply with regarding corruption detection, so that's left to the reader to pursue with their retail organisations legal department. INFRASTRUCTURE SERVICES These elements in the common architecture were pretty consistent across all of the Headless eCommerce solutions examined. These tended to be core elements setup in the retail organisations central location with the ability to control communication and overall integration for the complete architecture. A centralised integration element here is outside of the container platform integration elements discussed in the previous section and has a focus on more legacy integration aspects of an existing retail organisation.  The API management element here is for access to the headless e-commerce platform both by customers and also for third party connectivity to anything that your organisation might want to expose for use.  It goes without saying (almost), that a single-sign-on (SSO) server is essential for tying in the organisational tooling for authorisation and authentication to make use of components in the architecture. STORAGE SERVICES The storage services uncovered in this solution space was a fairly narrow with traditional relational database management system storage element and the open source Ceph storage solution.  There was not a lot of need for diversity in these services as the solution is squarely focused on the development and delivery pipeline for the e-commerce elements. WHAT'S NEXT This was just a short overview of the common generic elements that make up our architecture blueprint for the headless e-commerce imaging use case.  An overview of this series on the headless e-commerce portfolio architecture blueprint can be found here: 1. 2. 3. Example headless architectures Catch up on any articles you missed by following one of the links above. Next in this series, taking a look at an example headless architecture to provide you with a map for your own e-commerce solution. (Article co-authored by , Chief Architect Retail, Red Hat)&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/1vfsy29GmIk" height="1" width="1" alt=""/&gt;</content><dc:creator>Eric D. Schabell</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/YHEbyyin6ig/headless-ecommerce-common-architectural-elements.html</feedburner:origLink></entry><entry><title type="html">Design Tools Highlights on Kogito and Business Central, April 2021</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Ike7gzG_JqA/design-tools-highlights-on-kogito-and-business-central-april-2021.html" /><author><name>Eder Ignatowicz</name></author><id>https://blog.kie.org/2021/04/design-tools-highlights-on-kogito-and-business-central-april-2021.html</id><updated>2021-04-08T05:00:00Z</updated><content type="html">In the last months, the Design Tools Team released many cool new features on and . This post will do a quick overview of those. I hope you enjoy it! DASHBUILDER PROGRAMMATIC LAYOUT API Until the launch of this new API, the only way to create dashboards on Dashbuilder was via drag and drop on Layout Editor. Now, users can create their Dashboards, pages, components, and data sets directly on Java. Here is an example of the usage of such API: import org.dashbuilder.dataset.* import org.dashbuilder.displayer.DisplayerSettings; import org.dashbuilder.dsl.factory.component.ComponentFactory; import org.dashbuilder.dsl.factory.dashboard.DashboardFactory; import org.dashbuilder.dsl.model.* import org.dashbuilder.dsl.serialization.* import static java.util.Arrays.asList; import static org.dashbuilder.dataset.DataSetFactory.newDataSetBuilder; import static org.dashbuilder.displayer.DisplayerSettingsFactory.newBarChartSettings; import static org.dashbuilder.dsl.factory.navigation.NavigationFactory.*; import static org.dashbuilder.dsl.factory.page.PageFactory.*; public class SimpleDashboard { public static void main(String[] args) { DataSet dataSet = newDataSetBuilder().column("Country", ColumnType.LABEL) .column("Population", ColumnType.NUMBER) .row("Brazil", "211") .row("United States", "328") .row("Cuba", "11") .row("India", "1366") .row("China", "1398") .buildDataSet(); DisplayerSettings populationBar = newBarChartSettings().subType_Column() .width(800) .height(600) .dataset(dataSet) .column("Country") .column("Population") .buildSettings(); Page page = page("Countries Population", row("&lt;h3&gt; Countries Population &lt;/h3&gt;"), row(ComponentFactory.displayer(populationBar))); Navigation navigation = navigation(group("Countries Information", item(page))); Dashboard populationDashboard = DashboardFactory.dashboard(asList(page), navigation); DashboardExporter.get().export(populationDashboard, "/path/to/export.zip", ExportType.ZIP); } } hosted with ❤ by It will generate the following dashboard: We also introduced a “dev mode” to Dashbuilder Runtime, which automatically updates the Dashbuilder Runtime while developing and exporting the ZIP. Soon, we will publish a blog post with more details about this new feature, but meanwhile, a sneak peek of authoring workflow using it: DMN EDITOR – ENHANCED CODE-COMPLETION FOR LITERAL FEEL EXPRESSIONS Context-aware code completion is one of the most important features an IDE can provide to speed up coding, reduce typos and avoid other common mistakes. On Kogito Tooling 0.9.0 release, we introduced enhanced code-completion for Literal FEEL expressions. Check out this video: See this full for details. BPMN EDITOR – READ-ONLY MODE Since October, we also ship our editors as a standalone npm package. One of my favorite features of the standalone is the read-only mode because it is really useful for diagram visualization. Now, this mode is also supported on BPMN. The read-only mode is also used for the visualization of diagrams on our Chrome Extension. WORK ITEM DEFINITION SUPPORT IMPROVEMENTS To evolve our Work Item Definition support on Kogito Tooling BPMN editor, we included on 0.9.0 a lot of improvements in this area, primarily related to a better parsing mechanism and also better compatibility with Business Central. Now, we also search for wids and icons the ‘global’ directory used on BC. DASHBUILDER PROMETHEUS DATA SET PROVIDER Dashbuilder can read data from multiple types of data set sources, including CSV, SQL, ElasticSearch, and Kie Server. Since Business central 7.50.0 Final, we introduced a new type of provider for data sets: Prometheus. Prometheus is the standard for collecting metrics. It has connectors to very well-known systems, such as Kafka and metrics can be easily consumed from third-party systems. Furthermore, Kie Server by default also exports ! See a sample Dashboard based on Prometheus data: For a full description of this new feature, take a look at this . DASHBUILDER KAFKA DATA SET PROVIDER We also recently introduced Dashbuilder support for Kafka data sets. Kafka is the standard event streaming platform for cloud applications and RHPAM/Kogito systems expose metrics using Kafka, so this is the reason why we added Kafka support on Dashbuilder as a data set provider. Soon we will publish a blog post with more details about this new feature. DASHBUILDER TIME SERIES DISPLAYER This new component represents time-series metrics to smoothly support the new Prometheus data-set provider. Now, you can provide a custom dataset or Prometheus metrics and create visualizations of your time series data on a line or area chart using Dashbuilder. See this for more details. GWT 2.9 AND JDK11 UPGRADE After a collective effort involving many people from a lot of different teams, we also did two major upgrades on our codebase, supporting JDK11 compilation and GWT 2.9 on Business Central. This is a huge effort in a sizable codebase, so congrats to everyone involved! OTHER IMPORTANT ISSUES AND IMPROVEMENTS: BPMN: * Move the structure option to the top of the Data Type drop-down * – [BPMN] Open subprocesses in a new editor on BC only * Stunner – Text area for scripts is cropped/shifted * Stunner – Not all illegal characters are removed from Data Object name * : Erase of WID ‘nodes’ types DMN: * Move the structure option to the top of the Data Type drop-down * Allow sorting in guided decision table when clicking the column name SCESIM * Test Scenario does not support nested Enum type attributes * Scenario Simulation type error popup when constraint applied to DMN data type * Display actual test results instead of a generic message * SceSim runner does not display reason for failure THANK YOU TO EVERYONE INVOLVED! I would like to thank everyone involved with this release, from the excellent KIE Tooling Engineers to the lifesavers QEs and the UX people that help us look awesome! The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Ike7gzG_JqA" height="1" width="1" alt=""/&gt;</content><dc:creator>Eder Ignatowicz</dc:creator><feedburner:origLink>https://blog.kie.org/2021/04/design-tools-highlights-on-kogito-and-business-central-april-2021.html</feedburner:origLink></entry><entry><title type="html">This Week in JBoss - 8 April 2021</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Z_OYMtjy6vo/weekly-2021-04-08.html" /><category term="quarkus" /><category term="wildfly" /><category term="keycloak" /><category term="kogito" /><category term="elytron" /><category term="containers" /><category term="javascript" /><author><name>Don Naro</name><uri>https://www.jboss.org/people/don-naro</uri><email>do-not-reply@jboss.com</email></author><id>https://www.jboss.org/posts/weekly-2021-04-08.html</id><updated>2021-04-08T00:00:00Z</updated><content type="html">&lt;article class="" data-tags="quarkus, wildfly, keycloak, kogito, elytron, containers, javascript"&gt; &lt;h1&gt;This Week in JBoss - 8 April 2021&lt;/h1&gt; &lt;p class="preamble"&gt;&lt;/p&gt;&lt;p&gt;Hello! Welcome to another edition of the JBoss Editorial that brings you news and updates from our community.&lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;div class="sect1"&gt; &lt;h2 id="_release_roundup"&gt;Release roundup&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Let’s start things off with congrats to the teams on their hard work!&lt;/p&gt; &lt;div class="ulist square"&gt; &lt;ul class="square"&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://infinispan.org/blog/2021/04/07/infinispan-12-1-0-final"&gt;Infinispan 12.1.0.Final&lt;/a&gt; is released!&lt;br&gt; This version of Infinispan, codenamed Taedonggang, includes a bunch of new features and fixes. Be sure to check out the announcement and start using it right away.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/quarkus-1-13-0-final-released/"&gt;Quarkus 1.13&lt;/a&gt; and &lt;a href="https://quarkus.io/blog/quarkus-1-13-1-final-released/"&gt;Quarkus 1.13.1.Final&lt;/a&gt; are now available with loads of great new features and improvements.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;p&gt;Our very own Bela Ban has also recently finished off the work on &lt;a href="https://github.com/belaban/JGroups/tree/jgroups-4.2.12.Final"&gt;JGroups 4.2.12&lt;/a&gt; and &lt;a href="https://github.com/belaban/JGroups/tree/jgroups-5.1.6.Final"&gt;JGroups 5.1.6&lt;/a&gt;. While there might not be an "official" annoucement on his blog, you can check Bela’s commit history for details.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_from_the_community"&gt;From the community&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Let’s take a look at what’s been happening in the community since our last editorial.&lt;/p&gt; &lt;p&gt;First up is a post by Hao Wu, &lt;a href="https://blog.kie.org/2021/04/how-to-interact-with-business-processes-using-camel-routes.html"&gt;How to Interact with Business Processes Using Camel Routes&lt;/a&gt;, that neatly explains using Apache Camel to interact with business processes deployed in a KIE server.&lt;/p&gt; &lt;p&gt;Rebecca Searls, over at the RESTEasy blog, recently added a post titled &lt;a href="https://resteasy.github.io/2021/04/05/blog-ParamConverter-with-Quarkus/"&gt;JAX-RS ParamConverter with Quarkus&lt;/a&gt; that shows how to write RESTful services with Quarkus using the JAX-RS ParamConverter.&lt;/p&gt; &lt;p&gt;Eric Schabell has, yet again, delivered some great posts recently that demonstrate how community technology can solve real world business problems.&lt;/p&gt; &lt;p&gt;Finishing off a series of articles on point of sale architectures, Eric delves in a specific example in his post, &lt;a href="https://www.schabell.org/2021/03/point-of-sale-example-image-distribution-architecture.html"&gt;Point of sale - Example image distribution architecture&lt;/a&gt;. Be sure to check the links at the end of the post in case you missed any of the other articles in his architecture blueprint for point of sale imaging in retail.&lt;/p&gt; &lt;p&gt;Not one to rest, Eric kicks things off with another series to share an architectural blueprint for the use case of deploying a container-based eCommerce website while moving away from tightly coupled existing eCommerce platform.&lt;/p&gt; &lt;p&gt;This first article in this series is &lt;a href="https://www.schabell.org/2021/04/headless-ecommerce-an-architectural-introduction.html"&gt;Headless eCommerce - An architectural introduction&lt;/a&gt;, which gives you an outline for the use case.&lt;/p&gt; &lt;p&gt;Eric then continues the series with his post, &lt;a href="https://www.schabell.org/2021/04/headless-ecommerce-common-architectural-elements.html"&gt;Headless eCommerce - Common architectural elements&lt;/a&gt;. In this article, Eric goes into detail on common generic elements that make up the architecture blueprint for the headless eCommerce use case.&lt;/p&gt; &lt;p&gt;Stay tuned for the rest of Eric’s series! I’m sure there’s lots more great information on the way.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_red_hat_developer_network"&gt;Red Hat developer network&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;James Falkner talks us through what’s new with the beta release of JBoss EAP 7.4 beta, including an detailed look at security and management improvement. What to find out what’s going on? Take a few minutes and read his post, &lt;a href="https://developers.redhat.com/blog/2021/03/30/security-and-management-improvements-in-red-hat-jboss-enterprise-application-platform-7-4-beta/"&gt;Security and management improvements in Red Hat JBoss Enterprise Application Platform 7.4 Beta&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Pasquale Congiusti also breaks down Camel K’s Kamelets and shows how they simplify complex system integration in his post, &lt;a href="https://developers.redhat.com/blog/2021/04/02/design-event-driven-integrations-with-kamelets-and-camel-k/"&gt;Design event-driven integrations with Kamelets and Camel K&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_developers_on_film"&gt;Developers on film&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Get your popcorn ready and sit back to watch some videos from our community. Here are my top picks for this week’s editorial:&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/eW_1rj2EKYM"&gt;3 new Java tools to try in 2021&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/RZbLwBuKxuw"&gt;Quarkus Insights #43: Writing Quarkus Extensions&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/U_SqX5uMbds"&gt;Improving security with Istio | DevNation Tech Talk&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="author"&gt; &lt;pfe-avatar pfe-shape="circle" pfe-pattern="squares" pfe-src="/img/people/don-naro.png"&gt;&lt;/pfe-avatar&gt; &lt;span&gt;Don Naro&lt;/span&gt; &lt;/div&gt;&lt;/article&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Z_OYMtjy6vo" height="1" width="1" alt=""/&gt;</content><dc:creator>Don Naro</dc:creator><feedburner:origLink>https://www.jboss.org/posts/weekly-2021-04-08.html</feedburner:origLink></entry><entry><title type="html">How to Interact with Business Processes Using Camel Routes</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/r-9Wa4vZkgc/how-to-interact-with-business-processes-using-camel-routes.html" /><author><name>Hao Wu</name></author><id>https://blog.kie.org/2021/04/how-to-interact-with-business-processes-using-camel-routes.html</id><updated>2021-04-07T19:44:29Z</updated><content type="html">The JBPM KIE server has a rich set of REST APIs that allows control over business processes and other business assets. Interaction with business processes is straightforward and easily accessible. Usually these APIs are used by the Business Central component and custom applications. In this post I want to give a simple example of how to interact with business processes, deployed in a KIE server, using Apache Camel. Utilizing business processes in a camel route, as you will see, is pretty easy! There is an available component in Camel called simply the component. Both consumers and producers are supported. The consumer side has already been covered by Maciej in this excellent . My example will focus on the producer side. WHAT INTERACTIONS ARE AVAILABLE? The JBPM component uses exchange headers to hold the operations/commands used to interact with the KIE server. The query parameters in the URL holds the security and deployment information. The following is an example of an JBPM URL. jbpm:http://localhost:8080/kie-server/services/rest/server?userName=myuser&amp;amp;password=mypass&amp;amp;deploymentId=mydeployment That URL above will interact with the KIE server running on localhost port 8080, the container deployed as mydeployment, and using the user myuser and password mypass. Of course all these values can be parameterized. The following table shows some of the interactions available as of version Apache Camel 3.8. The header key for the operation header is JBPMConstants.OPERATION. All supported header keys are listed in the JBPMConstants class. OperationSupport HeadersDescriptionstartProcessPROCESS_ID PARAMETERSStart a process in the deployed container (in URL) and the process definition ID and any parameters.signalEventPROCESS_INSTANCE_ID EVENT_TYPE EVENTSignal a process instance with the signal (EVENT_TYPE) and payload (EVENT). If process instance ID is missing then the signal scope will be defaultgetProcessInstancePROCESS_INSTANCE_IDRetrieve the process instance using the ID. The resulting exchange body will be populated by a org.kie.server.api.model.instance.ProcessInstance object.completeWorkItemPROCESS_INSTANCE_ID WORK_ITEM_ID PARAMETERSComplete the work item using the parameters. You can find the complete list in the org.apache.camel.component.jbpm.JBPMProducer.Operation enum. SIMPLE EXAMPLE In this example we’ll be using the following versions: * * Install and start the JBPM KIE server. &gt; docker pull jboss/jbpm-server-full &gt; docker run -p 8080:8080 -p 8001:8001 -d --name jbpm-server-full jboss/jbpm-server-full:latest Log into Business Central () using wbadmin/wbadmin as the credentials. In the default MySpace, create a project call test-camel and a business process in it call test-camel-process. Add a process variable call data of type String. Add a script task to print out data. Save and deploy the project. To quickly stand up a Camel environment, we’ll be using Spring Boot. The following command will help you create the spring boot project: mvn archetype:generate \ -DarchetypeGroupId=org.apache.camel.archetypes \ -DarchetypeArtifactId=camel-archetype-spring-boot \ -DarchetypeVersion=3.8.0 In the resulting project, add the following dependency into the pom.xml file. &lt;dependency&gt; &lt;groupId&gt;org.apache.camel.springboot&lt;/groupId&gt; &lt;artifactId&gt;camel-jbpm-starter&lt;/artifactId&gt; &lt;/dependency&gt; Add the following to the application.properties file. server.port = 8280 jbpm.server.url = http://localhost:8080/kie-server/services/rest/server jbpm.server.user = wbadmin jbpm.server.pass = wbadmin jbpm.deployment.id = test-camel_1.0.0-SNAPSHOT jbpm.process.id = test-camel.test-camel-process jbpm.process.data = data Modify the MySpringBootRouter.java file to add some routes. The following code snippet will start a process. @Override public void configure() { from("timer:startprocess?delay=1000&amp;amp;period=5000") .to("direct:startprocess"); from("direct:startprocess") .setHeader(JBPMConstants.OPERATION, constant("CamelJBPMOperationstartProcess")) .setHeader(JBPMConstants.PROCESS_ID, simple("{{jbpm.process.id}}")) .process((Exchange exchange) -&gt; { String dataName = exchange.getContext().resolvePropertyPlaceholders("{{jbpm.process.data}}"); Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); params.put(dataName, "hello world"); exchange.getIn().setHeader(JBPMConstants.PARAMETERS, params); }) .to("jbpm:{{jbpm.server.url}}?userName={{jbpm.server.user}}&amp;amp;password={{jbpm.server.pass}}&amp;amp;deploymentId={{jbpm.deployment.id}}"); } The above example will send "hello world" as the data to start the process in the KIE server. By default without specifying JBPMConstants.OPERATION, the operation will be to start the process. The reason the operation is set to CamelJBPMOperationstartProcess is the operation is an aggregation of the value of JBPMConstants.OPERATION and the enum value defined in org.apache.camel.component.jbpm.JBPMProducer.Operation. Unfortunately we cannot use the operation enum directly because it’s not exposed publicly. The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/r-9Wa4vZkgc" height="1" width="1" alt=""/&gt;</content><dc:creator>Hao Wu</dc:creator><feedburner:origLink>https://blog.kie.org/2021/04/how-to-interact-with-business-processes-using-camel-routes.html</feedburner:origLink></entry><entry><title>Deploy Quarkus everywhere with Red Hat Enterprise Linux (RHEL)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/RHn0yrSElvY/" /><category term="Java" /><category term="Kubernetes" /><category term="Linux" /><category term="Quarkus" /><category term="cloud native java" /><category term="edge development" /><category term="Quarkus on RHEL" /><author><name>Syed M Shaaf</name></author><id>https://developers.redhat.com/blog/?p=888547</id><updated>2021-04-07T13:05:19Z</updated><published>2021-04-07T13:05:19Z</published><content type="html">&lt;p&gt;&lt;a target="_blank" rel="nofollow" href="/topics/enterprise-java/"&gt;Java&lt;/a&gt; is one of the most popular programming languages in the world. It has been among the &lt;a target="_blank" rel="nofollow" href="https://www.tiobe.com/tiobe-index/?hid=B4E841AA3BF5CD6D546F03D321E49994&amp;#38;wordfence_lh=1"&gt;top three languages&lt;/a&gt; used over the past two decades. Java powers millions of applications across many verticals and platforms. &lt;a target="_blank" rel="nofollow" href="/topics/linux/"&gt;Linux&lt;/a&gt; is widely deployed in data centers, edge networks, and the cloud.&lt;/p&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/blog/whats-new-quarkus-and-other-updates-red-hat-runtimes"&gt;Today we announced&lt;/a&gt; that &lt;a target="_blank" rel="nofollow" href="/products/quarkus/getting-started"&gt;Quarkus&lt;/a&gt; is now available for all &lt;a target="_blank" rel="nofollow" href="/products/rhel/overview"&gt;Red Hat Enterprise Linux (RHEL)&lt;/a&gt; customers. If you are running RHEL, you can easily use the &lt;a target="_blank" rel="nofollow" href="/products/quarkus/getting-started"&gt;Red Hat build of Quarkus&lt;/a&gt; in your Java applications. If you are developing applications on a &lt;a target="_blank" rel="nofollow" href="/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt; platform like &lt;a target="_blank" rel="nofollow" href="/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;, you can also use the Red Hat build of Quarkus &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/blog/introducing-quarkus-red-hat-openshift"&gt;as of November 2020&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;What is Quarkus, and how can you develop and deploy it on Red Hat Enterprise Linux? Read on to learn more. This article covers:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Using the Red Hat build of Quarkus on RHEL.&lt;/li&gt; &lt;li&gt;Running Quarkus in development mode.&lt;/li&gt; &lt;li&gt;Creating Java native executables with and without Podman.&lt;/li&gt; &lt;li&gt;Building application images with Podman on RHEL.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;What is the Red Hat build of Quarkus?&lt;/h2&gt; &lt;p&gt;If you are not familiar with Quarkus, its tagline is “supersonic, subatomic Java.” And yes, Java is super fast. With Quarkus, Java is even more lightweight and straightforward for developer use.&lt;/p&gt; &lt;p&gt;Quarkus is a Kubernetes-native &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/topics/cloud-native-apps/what-is-a-Java-framework"&gt;Java framework&lt;/a&gt; built for the Java Virtual Machine (JVM) and native compilation with GraalVM and Mandrel. Quarkus optimizes your Java code specifically for containers, making it an effective platform for &lt;a target="_blank" rel="nofollow" href="/topics/serverless-architecture/"&gt;serverless&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/topics/cloud"&gt;cloud&lt;/a&gt; environments like Red Hat OpenShift. Quarkus is designed to work with popular Java standards, frameworks, and libraries, including Eclipse MicroProfile, Spring, Apache Kafka, RESTEasy (JAX-RS), Hibernate ORM (JPA), Infinispan, Apache Camel.&lt;/p&gt; &lt;h2&gt;How to get started with Quarkus on RHEL&lt;/h2&gt; &lt;p&gt;There are multiple ways to start using Quarkus on RHEL. The &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_build_of_quarkus/"&gt;Quarkus documentation&lt;/a&gt; provides a list of different approaches. All you need to do is get the artifacts from Red Hat’s Maven repo.&lt;/p&gt; &lt;p&gt;For newbies, it’s simple to get started with the &lt;a target="_blank" rel="nofollow" href="https://code.quarkus.redhat.com"&gt;project generator&lt;/a&gt; using a web browser or Maven plug-in, as shown in Figure 1. Once configured, you can download the ZIP file or copy the Maven command to run Quarkus on your machine.&lt;/p&gt; &lt;div id="attachment_889647" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a3eed7454.png"&gt;&lt;img aria-describedby="caption-attachment-889647" class="wp-image-889647 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a3eed7454-1024x705.png" alt="The Quarkus project generator at https://code.quarkus.redhat.com." width="640" height="441" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a3eed7454-1024x705.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a3eed7454-300x207.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a3eed7454-768x529.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a3eed7454.png 1241w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-889647" class="wp-caption-text"&gt;Figure 1: The Quarkus project generator at code.quarkus.redhat.com.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Figure 1 shows all of the extensions that are supported in &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/support/offerings/techpreview/"&gt;technical preview&lt;/a&gt; and available for use. Quarkus has a vast ecosystem of extensions that help developers write applications, such as Kafka, Hibernate Reactive, Panache, and Spring.&lt;/p&gt; &lt;h2&gt;An example edge application&lt;/h2&gt; &lt;p&gt;It’s common for examples to use a CRUD application. However, we will look at an edge application that takes data from the device. This example illustrates a typical use case for Quarkus and RHEL at the network edge.&lt;/p&gt; &lt;p&gt;I have created a basic application that can run on a lightweight, resource-efficient RHEL server on the edge. Following is a breakdown of the data flow from devices to the front end. Figure 2 also shows the high-level architecture.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The devices send data to an MQTT broker.&lt;/li&gt; &lt;li&gt;Quarkus uses reactive messaging and channels to receive, process, and showcase those messages on a browser-based front end. Data comes in real time via a channel.&lt;/li&gt; &lt;li&gt;The front end uses REST and JavaScript.&lt;/li&gt; &lt;/ul&gt; &lt;div id="attachment_889667" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a47e734a7.png"&gt;&lt;img aria-describedby="caption-attachment-889667" class="wp-image-889667" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a47e734a7.png" alt="A high-level architecture diagram of Quarkus." width="640" height="641" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a47e734a7.png 622w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a47e734a7-150x150.png 150w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a47e734a7-300x300.png 300w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-889667" class="wp-caption-text"&gt;Figure 2: A high-level architecture diagram of Quarkus.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;To follow along or try it out, see the source code for this application in the &lt;a target="_blank" rel="nofollow" href="https://github.com/sshaaf/quarkus-edge-mqtt-demo"&gt;example repository&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s deploy this application on our RHEL server.&lt;/p&gt; &lt;h3&gt;Starting the MQTT broker with Podman&lt;/h3&gt; &lt;p&gt;RHEL has a daemonless container engine. What does this mean? RHEL uses Podman as the container engine. The Podman architecture allows you to run the containers under the user that is starting the container (the fork/exec model), and that user does not need root privileges. Because Podman has a daemonless architecture, a user running Podman can only see and modify their own containers. There is no common daemon that communicates with the command-line interface (CLI) tool.&lt;/p&gt; &lt;p&gt;We will use Podman throughout this example. You can learn more about Podman in this &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/building_running_and_managing_containers/index"&gt;guide to Linux containers on Red Hat Enterprise Linux 8&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;For this demo, we will use the Mosquitto message broker. Mosquitto is lightweight and suitable for all devices, from low-power, single-board computers to full servers. Let’s start an instance of Mosquitto using Podman:&lt;/p&gt; &lt;pre&gt;podman run --name mosquitto \ --rm -p "9001:9001" -p "1883:1883" \ eclipse-mosquitto:1.6.2&lt;/pre&gt; &lt;h3&gt;Building our application with Quarkus&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: This example assumes you have the latest Red Hat build of OpenJDK, &lt;a href="https://developers.redhat.com/products/openjdk/download"&gt;OpenJDK 11&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Next, we will spin up our application. You can use any integrated development environment (IDE) to develop with Quarkus. Most IDEs allow you to use the Quarkus Tools extension, which makes it easy for developers to create Quarkus applications.&lt;/p&gt; &lt;p&gt;To run Quarkus in development mode, follow these steps:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Open a terminal from your RHEL machine or any IDE.&lt;/li&gt; &lt;li&gt;&lt;code&gt;cd&lt;/code&gt; into the project directory: &lt;code&gt;https://github.com/sshaaf/quarkus-edge-mqtt-demo&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Run this command: &lt;code&gt;mvn quarkus&lt;/code&gt;.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;The output should look similar to what you see in Figure 3.&lt;/p&gt; &lt;div id="attachment_889687" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a4d958d3c.png"&gt;&lt;img aria-describedby="caption-attachment-889687" class="wp-image-889687 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a4d958d3c-1024x385.png" alt="Quarkus development mode output." width="640" height="241" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a4d958d3c-1024x385.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a4d958d3c-300x113.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a4d958d3c-768x289.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a4d958d3c.png 1079w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-889687" class="wp-caption-text"&gt;Figure 3: Quarkus development mode output.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Open your browser and navigate to &lt;a target="_blank" rel="nofollow" href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt;. You should see the main page for our application reporting real-time data from our emulated device, as shown in Figure 4. In this case, our emulated device, ESP8266-01, throws temperature and heat measurements in JSON format from the device into the MQTT broker. The JSON is then picked up as a reactive channel and throws that data out after processing into the stream. The browser reads the stream and displays the data in real time. You can easily change the emulated device to a real one; however, the data thrown must be in the correct JSON format.&lt;/p&gt; &lt;div id="attachment_889697" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a4fc880e9.png"&gt;&lt;img aria-describedby="caption-attachment-889697" class="wp-image-889697 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a4fc880e9-1024x521.png" alt="Real-time data from the emulated device." width="640" height="326" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a4fc880e9-1024x521.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a4fc880e9-300x153.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a4fc880e9-768x391.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-889697" class="wp-caption-text"&gt;Figure 4: Real-time data from the emulated device.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Using Quarkus in development mode&lt;/h3&gt; &lt;p&gt;Now you have a running application in development mode on your RHEL machine. What do developers gain from using Quarkus in development mode? Benefits include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Zero configuration, live code, and the ability to reload in the blink of an eye. If you change any of your Java files, you don’t need to reload the entire environment. Quarkus understands!&lt;/li&gt; &lt;li&gt;Based on standards, but not limited.&lt;/li&gt; &lt;li&gt;Unified configuration.&lt;/li&gt; &lt;li&gt;Streamlined code for the 80% common usages, flexible for the 20%.&lt;/li&gt; &lt;li&gt;Easy native executable generation.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The Red Hat build of Quarkus &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_build_of_quarkus/1.11/html/release_notes_for_red_hat_build_of_quarkus_1.11/index"&gt;1.11 release&lt;/a&gt; introduced an awesome developer console called the Quarkus Dev UI. You can access the Quarkus Dev UI in dev mode by navigating to &lt;code&gt;http://localhost:8080/q/dev&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;In the Quarkus Dev UI, select &lt;strong&gt;SmallRye Reactive Messaging Channels&lt;/strong&gt; from the extensions shown in Figure 5.&lt;/p&gt; &lt;div id="attachment_889707" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a53c7f6e1.png"&gt;&lt;img aria-describedby="caption-attachment-889707" class="wp-image-889707" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a53c7f6e1.png" alt="Extensions listed in the Quarkus Dev UI." width="640" height="396" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a53c7f6e1.png 849w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a53c7f6e1-300x186.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a53c7f6e1-768x475.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-889707" class="wp-caption-text"&gt;Figure 5: Extensions in the Quarkus Dev UI.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;From there, you will see the reactive streams that our edge device is using (see Figure 6).&lt;/p&gt; &lt;div id="attachment_889717" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a582a8ff3.png"&gt;&lt;img aria-describedby="caption-attachment-889717" class="wp-image-889717 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a582a8ff3-1024x177.png" alt="Reactive streams extensions and list of streams." width="640" height="111" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a582a8ff3-1024x177.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a582a8ff3-300x52.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a582a8ff3-768x133.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a582a8ff3.png 1535w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-889717" class="wp-caption-text"&gt;Figure 6: Reactive streams extensions and list of streams.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;For more details about development mode, see &lt;a target="_blank" rel="nofollow" href="/blog/2021/02/11/enhancing-the-development-loop-with-quarkus-remote-development/"&gt;Enhancing the development loop with Quarkus remote development&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Build the application image with Podman&lt;/h3&gt; &lt;p&gt;You can create a native binary for your platform by running the &lt;code&gt;-Pnative&lt;/code&gt; directive with Maven.&lt;/p&gt; &lt;p&gt;However, you might not have the entire compilation environment set up—for instance, you haven&amp;#8217;t installed Mandrel or GraalVM. In that case, you can use your container runtime to build the native image. The simplest way to do this is by running the following command:&lt;/p&gt; &lt;pre&gt;mvn package -Pnative -Dquarkus.native.container-build=true  -Dquarkus.native.container-runtime=podman&lt;/pre&gt; &lt;p&gt;Quarkus will pick up the default container runtime (in this case, Podman).&lt;/p&gt; &lt;p&gt;You can also specify &lt;code&gt;-Dquarkus.native.container-runtime=podman&lt;/code&gt; to explicitly select Podman. It takes a few minutes to build the image for optimizing the Quarkus application through dead code elimination, class scanning, reflections, and build proxies. Quarkus will optimize the application not just for native images, but also for JVM mode. As a result, you will see fast startup times and a low memory footprint. Figure 7 shows the process from compilation to executables. For more details, take a look at the &lt;a target="_blank" rel="nofollow" href="https://quarkus.io/blog/tag/performance/"&gt;Quarkus performance blogs&lt;/a&gt;.&lt;/p&gt; &lt;div id="attachment_889727" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a5bfda0fc.png"&gt;&lt;img aria-describedby="caption-attachment-889727" class="wp-image-889727" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a5bfda0fc.png" alt="The Quarkus build process." width="640" height="255" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a5bfda0fc.png 986w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a5bfda0fc-300x120.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_6065a5bfda0fc-768x306.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-889727" class="wp-caption-text"&gt;Figure 7: The Quarkus build process.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;You can also limit the amount of memory used during native compilation by setting the &lt;code&gt;quarkus.native.native-image-xmx&lt;/code&gt; configuration property. Note that setting low memory limits might increase the build time. You can also use Podman to create a container image with our binary.&lt;/p&gt; &lt;p&gt;Under &lt;code&gt;src/main&lt;/code&gt;, Quarkus pregenerates different Dockerfiles for your application. Here, we will use the native Dockerfile because we already created a native binary. Execute the following command in our project home directory:&lt;/p&gt; &lt;pre&gt;podman build -f src/main/docker/Dockerfile.native -t sshaaf/quarkus-edge-mqtt . &lt;/pre&gt; &lt;p&gt;Finally, run the following command to launch the container on your RHEL machine:&lt;/p&gt; &lt;pre&gt;podman run -i --rm -p 8080:8080 sshaaf/quarkus-edge-mqtt &lt;/pre&gt; &lt;p&gt;Return to &lt;a target="_blank" rel="nofollow" href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt;. You should now see the application running and displaying incoming data from our device.&lt;/p&gt; &lt;h2&gt;Quarkus resources&lt;/h2&gt; &lt;p&gt;Quarkus is a Java framework suitable for multiple use cases, whether you are running applications on edge gateways, creating serverless functions, or deploying on cloud environments like Kubernetes and Red Hat OpenShift. Quarkus is easy and enjoyable for developers to use, and it improves Java application performance for the cloud.&lt;/p&gt; &lt;p&gt;If you want to learn more about Quarkus, here are some helpful resources:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_build_of_quarkus/1.11/html/release_notes_for_red_hat_build_of_quarkus_1.11/index"&gt;Release notes for Red Hat build of Quarkus 1.11&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_build_of_quarkus/1.11/html/getting_started_with_quarkus/index"&gt;Getting started with Quarkus&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_build_of_quarkus/"&gt;Product documentation for Red Hat build of Quarkus 1.11&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="/courses/quarkus"&gt;Developing with Quarkus course&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="/books/practising-quarkus"&gt;Practising Quarkus e-book&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="/books/understanding-quarkus"&gt;Understanding Quarkus e-book&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="/cheat-sheets/quarkus-kubernetes-i"&gt;Quarkus Cheat Sheet&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://dzone.com/refcardz/quarkus-1?chapter=1"&gt;Quarkus DZone RefCard&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="blog/2019/03/07/quarkus-next-generation-kubernetes-native-java-framework/"&gt;Introducing Quarkus: A next-generation Kubernetes native Java framework&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/07/deploy-quarkus-everywhere-with-red-hat-enterprise-linux-rhel/"&gt;Deploy Quarkus everywhere with Red Hat Enterprise Linux (RHEL)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/RHn0yrSElvY" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Java is one of the most popular programming languages in the world. It has been among the top three languages used over the past two decades. Java powers millions of applications across many verticals and platforms. Linux is widely deployed in data centers, edge networks, and the cloud. Today we announced that Quarkus is now [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/07/deploy-quarkus-everywhere-with-red-hat-enterprise-linux-rhel/"&gt;Deploy Quarkus everywhere with Red Hat Enterprise Linux (RHEL)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/04/07/deploy-quarkus-everywhere-with-red-hat-enterprise-linux-rhel/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">888547</post-id><dc:creator>Syed M Shaaf</dc:creator><dc:date>2021-04-07T13:05:19Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/04/07/deploy-quarkus-everywhere-with-red-hat-enterprise-linux-rhel/</feedburner:origLink></entry><entry><title type="html">Infinispan 12.1.0.Final</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/vAW-KxIGzPQ/infinispan-12-1-0-final" /><author><name>Tristan Tarrant</name></author><id>/blog/2021/04/07/infinispan-12-1-0-final</id><updated>2021-04-07T12:00:00Z</updated><content type="html">Dear Infinispan community, As a belated surprise in your chocolate egg this year is a brand new final release. Infinispan 12.1 includes a bunch of new features and fixes. OUT-OF-THE-BOX AUTHORIZATION IN THE SERVER The biggest change is the fact that the server now enables authorization right from the start, including a set of predefined roles. By default this only affects management ops and it can be easily disabled. Head over to for details on this feature and how to tune it to your own needs. CONFIGURATION Infinispan can now load configuration as YAML, as well as XML and JSON. SOFT-INDEX FILE STORE The Soft-Index File Store (or SIFS for short) is one of our file-based stores, and it has received a number of improvements such as segmentation, non-blocking and requiring no additional threads. Additionally, if you are lucky enough to have some persistent memory hardware, this file-store can support it via the very awesome . We hope to make this our default file-store in the future (replacing the Single File Store). SERVER PROTOCOL MANAGEMENT You can now enable/disable protocol endpoints at runtime or use for fine-grained access control. CONSOLE The console is now fully aware of the server authorization roles (if enabled) and many fixes are included. CLI The CLI is now available as for Linux and MacOS. CROSS SITE REPLICATION You can now enable automatic Cross Site for asynchronous backup strategy. SPRING Our Spring Cache and Spring Session integration now allows user keys and values to be stored in format. However, full integration with the Infinispan Spring Boot Starter is landing in the next minor release. Stay tuned! MARSHALLING/PROTOBUF The latest ProtoStream release 4.4.0.Beta3 includes support for marshalling arrays and collections, built-in support for several community requested types (UUID, BigDEcimal,… ), a new method in ProtobufUtil for computing message size (without actually encoding the message) and a lot of bug fixes. This release also provides it’s own protobuf encoder and removes the dependency on protobuf-java artifact which was previously used for encoding the stream (without being exposed by the API). IMAGES We now provide an image containing a natively compiled version of the Infinispan CLI at quay.io/infinispan/cli OPERATOR In addition to numerous fixes, the operator has added many new features. Most notably: * Grafana Dashboard * Batch CR * Custom library support * Custom labels on Resources created by Operator * Disable Authentication Option * Decouple user and operator endpoint authentication DOCUMENTATION We’ve made a lot of updates to our documentation this release, with lots more task-oriented content for new features and capabilities. Server credential stores, refactored authorization (RBAC) configuration, Operator Batch CR, Backup and Restore CRs, custom code deployments, automatic cross-site state transfer, querying values, configuring Protobuf annotations for marshalling… Hopefully you’ll find all the answers you need for using Infinispan 12.1. One of the big highlights for docs in this release are the new tabbed configuration snippets we’re going to start adding. Right now you can find an example of tabbed configuration in the REST API docs here: We’ve also done a lot of housekeeping in this release to make sure configuration examples are up to date and valid. In the next release you can expect to see more improvements there as well as a new title to improve our documentation around encoding and how Infinispan uses Protobuf. As always, thanks for reading and get in touch if you have comments, feedback, or suggestions on our documentation. RELEASE NOTES AND UPGRADING You can look at the detailed to see what has changed since CR1. If you are upgrading from a previous version of Infinispan, please checkout our . WHAT’S NEXT ? Our next release, 13.0, should happen during the summer, and will hopefully introduce a new API which will make using Infinispan much easier, as well as a number of other improvements across the board. As usual, look out for blog postings about upcoming highlights. If you’d like to contribute, just get in touch.&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/vAW-KxIGzPQ" height="1" width="1" alt=""/&gt;</content><dc:creator>Tristan Tarrant</dc:creator><feedburner:origLink>http://tools.jboss.org/blog/2021/04/07/infinispan-12-1-0-final</feedburner:origLink></entry><entry><title>Securely connect Red Hat Integration Service Registry with Red Hat AMQ Streams</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/PEfroeCHkfw/" /><category term="Event-Driven" /><category term="Java" /><category term="Kubernetes" /><category term="Security" /><category term="amq streams" /><category term="Apicurio" /><category term="Authentication" /><category term="Authorization" /><category term="Kafka cluster" /><author><name>Roman Martin Gil</name></author><id>https://developers.redhat.com/blog/?p=779427</id><updated>2021-04-07T07:00:20Z</updated><published>2021-04-07T07:00:20Z</published><content type="html">&lt;p&gt;&lt;a target="_blank" rel="nofollow" href="/blog/2019/12/16/getting-started-with-red-hat-integration-service-registry/"&gt;Red Hat Integration Service Registry&lt;/a&gt; is a datastore based on the &lt;a target="_blank" rel="nofollow" href="https://www.apicur.io/"&gt;Apicurio&lt;/a&gt; open source project. In my previous article, I showed you &lt;a target="_blank" rel="nofollow" href="/blog/2021/02/15/integrating-spring-boot-with-red-hat-integration-service-registry/"&gt;how to integrate Spring Boot with Service Registry&lt;/a&gt;. In this article, you&amp;#8217;ll learn how to connect Service Registry to a secure &lt;a target="_blank" rel="nofollow" href="/products/amq/overview"&gt;Red Hat AMQ Streams&lt;/a&gt; cluster.&lt;/p&gt; &lt;h2&gt;Connecting Service Registry with AMQ Streams&lt;/h2&gt; &lt;p&gt;Service Registry includes a set of pluggable storage options for storing APIs, rules, and validations. The &lt;a target="_blank" rel="nofollow" href="/topics/kafka-kubernetes"&gt;Kafka&lt;/a&gt;-based storage option, provided by &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/resources/amq-streams-datasheet"&gt;Red Hat AMQ Streams&lt;/a&gt;, is suitable for production environments where persistent storage is configured for a Kafka cluster running on &lt;a target="_blank" rel="nofollow" href="/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Security is not optional in a production environment, and AMQ Streams must provide it for each component you connect to. Security is defined by &lt;em&gt;authentication&lt;/em&gt;, which ensures a secure client connection to the Kafka cluster, and &lt;em&gt;authorization&lt;/em&gt;, specifying which users can access which resources. I will show you how to set up authentication and authorization with AMQ Streams and Service Registry.&lt;/p&gt; &lt;h2&gt;The AMQ Streams Operators&lt;/h2&gt; &lt;p&gt;AMQ Streams and Service Registry provide a set of &lt;a target="_blank" rel="nofollow" href="/topics/kubernetes/operators"&gt;OpenShift Operators&lt;/a&gt; available from the &lt;a target="_blank" rel="nofollow" href="https://operatorhub.io/"&gt;OpenShift OperatorHub&lt;/a&gt;. Developers use these Operators to package, deploy, and manage OpenShift application components.&lt;/p&gt; &lt;p&gt;The &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.7/html-single/amq_streams_on_openshift_overview/index#overview-components_str"&gt;AMQ Streams Operators&lt;/a&gt; provide a set of custom resource definitions (CRDs) to describe the components of a Kafka deployment. These objects—namely, Zookeeper, Brokers, Users, and Connect—provide the API that we use to manage our Kafka cluster. AMQ Streams Operators manage authentication, authorization, and the user&amp;#8217;s life cycle.&lt;/p&gt; &lt;p&gt;The AMQ Streams &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.7/html-single/amq_streams_on_openshift_overview/index#overview-components-cluster-operator-str"&gt;Cluster Operator&lt;/a&gt; manages the &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.7/html-single/using_amq_streams_on_openshift/index#type-Kafka-reference"&gt;Kafka schema reference&lt;/a&gt; resource, which declares the Kafka topology and features to use.&lt;/p&gt; &lt;p&gt;The AMQ Streams &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.7/html-single/amq_streams_on_openshift_overview/index#overview-concepts-user-operator-str"&gt;User Operator&lt;/a&gt; manages the &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.7/html-single/using_amq_streams_on_openshift/index#type-KafkaUser-reference"&gt;KafkaUser schema reference&lt;/a&gt; resource. This resource declares a user for an instance of AMQ Streams, including the user&amp;#8217;s authentication, authorization, and quota definitions.&lt;/p&gt; &lt;h2&gt;The Service Registry Operator&lt;/h2&gt; &lt;p&gt;The &lt;a target="_blank" rel="nofollow" href="https://www.apicur.io/registry/docs/apicurio-registry/1.3.3.Final/getting-started/assembly-installing-registry-openshift.html#installing-registry-operatorhub"&gt;Service Registry Operator&lt;/a&gt; provides a set of CRDs to describe service registry deployment components such as storage, security, and replicas. Together, these objects provide the API to manage a Service Registry instance.&lt;/p&gt; &lt;p&gt;The Service Registry Operator uses the &lt;a target="_blank" rel="nofollow" href="https://github.com/Apicurio/apicurio-registry-operator/blob/master/deploy/crds/apicur.io_apicurioregistries_crd.yaml"&gt;ApicurioRegistry schema reference&lt;/a&gt; to manage the service registry life cycle. The &lt;code&gt;ApicurioRegistry&lt;/code&gt; declares the service registry topology and main features. The Apicurio Operator manages the &lt;code&gt;ApicurioRegistry&lt;/code&gt; object.&lt;/p&gt; &lt;h2&gt;Authentication with AMQ Streams&lt;/h2&gt; &lt;p&gt;Red Hat AMQ Streams supports the following authentication mechanisms:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;SASL SCRAM-SHA-512&lt;/li&gt; &lt;li&gt;Transport Layer Security (TLS) client authentication&lt;/li&gt; &lt;li&gt;OAuth 2.0 token-based authentication&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;These mechanisms are declared in the &lt;code&gt;authentication&lt;/code&gt; block in each listener&amp;#8217;s &lt;code&gt;Kafka&lt;/code&gt; definition. Each listener implements the authentication mechanism defined, so the client applications must authenticate with the mechanism identified.&lt;/p&gt; &lt;h3&gt;Two ways to authenticate an AMQ Streams cluster&lt;/h3&gt; &lt;p&gt;First off, let&amp;#8217;s see how to activate each mechanism in the AMQ Streams cluster. We need to identify in Service Registry the authentication mechanism activated in the AMQ Streams cluster. Service Registry only allows &lt;a target="_blank" rel="nofollow" href="https://tools.ietf.org/id/draft-melnikov-scram-sha-512-01.html"&gt;SCRAM-SHA-512&lt;/a&gt; and TLS as authentication mechanisms. I&amp;#8217;ll show you how to configure authentication using each of these mechanisms.&lt;/p&gt; &lt;h4&gt;Authenticating a Kafka cluster with SCRAM-SHA-512&lt;/h4&gt; &lt;p&gt;The following &lt;code&gt;Kafka&lt;/code&gt; definition declares a Kafka cluster secured with SCRAM-SHA-512 authentication for the secured listener (secured using the TLS protocol):&lt;/p&gt; &lt;pre&gt;apiVersion: kafka.strimzi.io/v1beta1 kind: Kafka metadata: name: my-kafka spec: kafka: listeners: tls: authentication: type: scram-sha-512 &lt;/pre&gt; &lt;p&gt;Applying this configuration creates a set of secrets where the TLS certificates are stored. The secret we need to know to allow the secured connections is declared as &lt;code&gt;my-kafka-cluster-ca-cert&lt;/code&gt;. Note that we will need this value later on.&lt;/p&gt; &lt;p&gt;The following &lt;code&gt;KafkaUser&lt;/code&gt; definition declares a Kafka user with SCRAM-SHA-512 authentication:&lt;/p&gt; &lt;pre&gt;apiVersion: kafka.strimzi.io/v1beta1 kind: KafkaUser metadata: name: service-registry-scram labels: strimzi.io/cluster: my-kafka spec: authentication: type: scram-sha-512 &lt;/pre&gt; &lt;p&gt;Applying this configuration creates a secret (the user&amp;#8217;s name) and stores it where the user credentials are stored. This secret contains the generated password to authenticate to the Kafka cluster:&lt;/p&gt; &lt;pre&gt;$ oc get secrets NAME TYPE DATA AGE service-registry-scram Opaque 1 4s &lt;/pre&gt; &lt;h4&gt;Authenticating a Kafka cluster with TLS&lt;/h4&gt; &lt;p&gt;The following &lt;code&gt;Kafka&lt;/code&gt; definition declares a Kafka cluster secured with TLS authentication for the secured listener (secured with the TLS protocol):&lt;/p&gt; &lt;pre&gt;apiVersion: kafka.strimzi.io/v1beta1 kind: Kafka metadata: name: my-kafka spec: kafka: listeners: tls: authentication: type: tls &lt;/pre&gt; &lt;p&gt;Applying this configuration creates a set of secrets where the TLS certificates are stored. The secret we need to know to allow the secured connections is declared as &lt;code&gt;my-kafka-cluster-ca-cert&lt;/code&gt;. Note that we will need this value later on.&lt;/p&gt; &lt;p&gt;The following &lt;code&gt;KafkaUser&lt;/code&gt; definition declares a Kafka user with TLS authentication:&lt;/p&gt; &lt;pre&gt;apiVersion: kafka.strimzi.io/v1beta1 kind: KafkaUser metadata: name: service-registry-tls labels: strimzi.io/cluster: my-kafka spec: authentication: type: tls &lt;/pre&gt; &lt;p&gt;Applying this configuration creates a secret (the user&amp;#8217;s name) and stores it where the user credentials are stored. This secret contains the valid client certificates to authenticate to the Kafka cluster:&lt;/p&gt; &lt;pre&gt;$ oc get secrets NAME TYPE DATA AGE Service-registry-tls Opaque 1 4s &lt;/pre&gt; &lt;h3&gt;Service Registry authentication&lt;/h3&gt; &lt;p&gt;To identify the authentication mechanism activated in the AMQ Streams cluster, we need to deploy the Service Registry accordingly, using the &lt;code&gt;ApicurioRegistry&lt;/code&gt; definition:&lt;/p&gt; &lt;pre&gt;apiVersion: apicur.io/v1alpha1 kind: ApicurioRegistry metadata: name: service-registry spec: configuration: persistence: "streams" streams: &lt;strong&gt;bootstrapServers&lt;/strong&gt;: "my-kafka-kafka-bootstrap:&lt;strong&gt;9093&lt;/strong&gt;" &lt;/pre&gt; &lt;p style="padding-left: 40px"&gt;&lt;b&gt;Note&lt;/b&gt;: At the time of this writing, Service Registry can only connect to the AMQ Streams TLS listener (normally in port 9093) when the authentication mechanism is activated in that listener. The &lt;code&gt;ApicurioRegistry&lt;/code&gt; definition&amp;#8217;s &lt;code&gt;boostrapServers&lt;/code&gt; property must point to that listener port.&lt;/p&gt; &lt;h4&gt;Service Registry authentication using SCRAM-SHA-512&lt;/h4&gt; &lt;p&gt;The following &lt;code&gt;ApicurioRegistry&lt;/code&gt; definition declares a secured connection with a user with SCRAM-SHA-512 authentication:&lt;/p&gt; &lt;pre&gt;apiVersion: apicur.io/v1alpha1 kind: ApicurioRegistry metadata: name: service-registry spec: configuration: persistence: "streams" streams: bootstrapServers: "my-kafka-kafka-bootstrap:9093" security: scram: user: service-registry-scram passwordSecretName: service-registry-scram truststoreSecretName: my-kafka-cluster-ca-cert&lt;/pre&gt; &lt;p&gt;We need to identify the following values in this object:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;b&gt;User&lt;/b&gt;: The username to be securely connected.&lt;/li&gt; &lt;li&gt;&lt;b&gt;PasswordSecretName&lt;/b&gt;:  The name of the secret where the password is saved.&lt;/li&gt; &lt;li&gt;&lt;b&gt;TruststoreSecretName&lt;/b&gt;: The name of secret with the certificate authority (CA) certificates for the deployed Kafka cluster.&lt;/li&gt; &lt;/ul&gt; &lt;h4&gt;Service Registry authentication using TLS&lt;/h4&gt; &lt;p&gt;The following &lt;code&gt;ApicurioRegistry&lt;/code&gt; definition declares a secured connection with a user with a TLS authentication:&lt;/p&gt; &lt;pre&gt;apiVersion: apicur.io/v1alpha1 kind: ApicurioRegistry metadata: name: service-registry spec: configuration: persistence: "streams" streams: bootstrapServers: "my-kafka-kafka-bootstrap:9093" security: tls: keystoreSecretName: service-registry-tls truststoreSecretName: my-kafka-cluster-ca-cert&lt;/pre&gt; &lt;p&gt;The values that we need to identify in this object are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;b&gt;KeystoreSecretName&lt;/b&gt;: The name of the user secret with the client certificates.&lt;/li&gt; &lt;li&gt;&lt;b&gt;TruststoreSecretName&lt;/b&gt;: The name of the secret with the CA certificates for the deployed Kafka cluster.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Authorization with AMQ Streams&lt;/h2&gt; &lt;p&gt;AMQ Streams supports authorization using &lt;code&gt;SimpleACLAuthorizer&lt;/code&gt; globally for all listeners used for client connections. This mechanism uses access control lists (ACLs) to define which users have access to which resources.&lt;/p&gt; &lt;p&gt;Denial is the default access control if authorization is applied in the Kafka cluster. The listener must declare different rules for each user that wishes to operate within the Kafka cluster.&lt;/p&gt; &lt;h3&gt;The Kafka definition&lt;/h3&gt; &lt;p&gt;The following &lt;code&gt;Kafka&lt;/code&gt; definition activates authorization in the Kafka cluster:&lt;/p&gt; &lt;pre&gt;apiVersion: kafka.strimzi.io/v1beta1 kind: Kafka metadata: name: my-kafka spec: kafka: authorization: type: simple&lt;/pre&gt; &lt;h3&gt;The KafkaUser definition&lt;/h3&gt; &lt;p&gt;An ACL is declared for each user in the &lt;code&gt;KafkaUser&lt;/code&gt; definition. The &lt;code&gt;acls&lt;/code&gt; section (see below) includes a list of resources, where each resource is declared as a new rule:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Resource type&lt;/strong&gt;: Identifies the type of object managed in Kafka; objects include topics, consumer groups, clusters, transaction IDs, and delegation tokens.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Resource name&lt;/strong&gt;: Identifies the resource where the rule is applied. The resource name could be defined as a &lt;i&gt;literal&lt;/i&gt;, to identify one resource, or as a &lt;i&gt;prefix pattern&lt;/i&gt;, to identify a list of resources.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Operation&lt;/strong&gt;: Declares the kind of operations allowed. A full list of operations available for each resource type is available &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.7/html-single/using_amq_streams_on_openshift/index#simple-acl-str"&gt;here&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;For a Service Registry user to work successfully with our secured AMQ Streams cluster, we must declare the following rules specifying what the user is allowed to do:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Read its own consumer group.&lt;/li&gt; &lt;li&gt;Create, read, write, and describe on a global ID topic (&lt;code&gt;global-id-topic&lt;/code&gt;).&lt;/li&gt; &lt;li&gt;Create, read, write, and describe on a storage topic (&lt;code&gt;storage-topic&lt;/code&gt;).&lt;/li&gt; &lt;li&gt;Create, read, write, and describe on its own local changelog topics.&lt;/li&gt; &lt;li&gt;Describe and write transactional IDs on its own local group.&lt;/li&gt; &lt;li&gt;Read on a consumer offset topic (&lt;code&gt;__consumer_offsets&lt;/code&gt;).&lt;/li&gt; &lt;li&gt;Read on a transaction state topic (&lt;code&gt;__transaction_state&lt;/code&gt;).&lt;/li&gt; &lt;li&gt;Write idempotently on a cluster.&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;The ACL definition&lt;/h3&gt; &lt;p&gt;Here is an example ACL definition:&lt;/p&gt; &lt;pre&gt; acls: # Group Id to consume information for the different topics used by the Service Registry. # Name equals to metadata.name property in ApicurioRegistry object - resource: type: group name: service-registry operation: Read # Rules for the Global global-id-topic - resource: type: topic name: global-id-topic operation: Read - resource: type: topic name: global-id-topic operation: Describe - resource: type: topic name: global-id-topic operation: Write - resource: type: topic name: global-id-topic operation: Create # Rules for the Global storage-topic - resource: type: topic name: storage-topic operation: Read - resource: type: topic name: storage-topic operation: Describe - resource: type: topic name: storage-topic operation: Write - resource: type: topic name: storage-topic operation: Create # Rules for the local topics created by our Service Registry instance # Prefix value equals to metadata.name property in ApicurioRegistry object - resource: type: topic name: service-registry- patternType: prefix operation: Read - resource: type: topic name: service-registry- patternType: prefix operation: Describe - resource: type: topic name: service-registry- patternType: prefix operation: Write - resource: type: topic name: service-registry- patternType: prefix operation: Create # Rules for the local transactionalsIds created by our Service Registry instance # Prefix equals to metadata.name property in ApicurioRegistry object - resource: type: transactionalId name: service-registry- patternType: prefix operation: Describe - resource: type: transactionalId name: service-registry- patternType: prefix operation: Write # Rules for internal Apache Kafka topics - resource: type: topic name: __consumer_offsets operation: Read - resource: type: topic name: __transaction_state operation: Read # Rules for Cluster objects - resource: type: cluster operation: IdempotentWrite&lt;/pre&gt; &lt;p&gt;Note that activating authorization in AMQ Streams does not affect the &lt;code&gt;ApicurioRegistry&lt;/code&gt; definition. It is only related to the correct ACL definitions in the &lt;code&gt;KafkaUser&lt;/code&gt; objects.&lt;/p&gt; &lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;Connecting Service Registry&amp;#8217;s security capabilities to secure AMQ Streams clusters enables your production environment to prompt a warning about your security requirements. This article introduced the Service Registry and AMQ Streams components concerned with security requirements and showed you how to apply them successfully.&lt;/p&gt; &lt;p&gt;For a deeper understanding and analysis, please refer to the following references:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.7/html-single/using_amq_streams_on_openshift/index#security-str"&gt;Using AMQ Streams on OpenShift, Chapter 12: Security&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.7/html-single/using_amq_streams_on_openshift/index#assembly-using-the-user-operator-str"&gt;Using the User Operator of AMQ Streams&lt;/a&gt; (Red Hat Integration 2020-Q2 documentation)&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_integration/2020-q2/html/getting_started_with_service_registry/index"&gt;Getting started with Service Registry&lt;/a&gt; (Red Hat Integration 2020-Q2 documentation)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F07%2Fsecurely-connect-red-hat-integration-service-registry-with-red-hat-amq-streams%2F&amp;#38;linkname=Securely%20connect%20Red%20Hat%20Integration%20Service%20Registry%20with%20Red%20Hat%20AMQ%20Streams" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F07%2Fsecurely-connect-red-hat-integration-service-registry-with-red-hat-amq-streams%2F&amp;#38;linkname=Securely%20connect%20Red%20Hat%20Integration%20Service%20Registry%20with%20Red%20Hat%20AMQ%20Streams" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F07%2Fsecurely-connect-red-hat-integration-service-registry-with-red-hat-amq-streams%2F&amp;#38;linkname=Securely%20connect%20Red%20Hat%20Integration%20Service%20Registry%20with%20Red%20Hat%20AMQ%20Streams" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F07%2Fsecurely-connect-red-hat-integration-service-registry-with-red-hat-amq-streams%2F&amp;#38;linkname=Securely%20connect%20Red%20Hat%20Integration%20Service%20Registry%20with%20Red%20Hat%20AMQ%20Streams" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F07%2Fsecurely-connect-red-hat-integration-service-registry-with-red-hat-amq-streams%2F&amp;#38;linkname=Securely%20connect%20Red%20Hat%20Integration%20Service%20Registry%20with%20Red%20Hat%20AMQ%20Streams" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F07%2Fsecurely-connect-red-hat-integration-service-registry-with-red-hat-amq-streams%2F&amp;#38;linkname=Securely%20connect%20Red%20Hat%20Integration%20Service%20Registry%20with%20Red%20Hat%20AMQ%20Streams" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F07%2Fsecurely-connect-red-hat-integration-service-registry-with-red-hat-amq-streams%2F&amp;#38;linkname=Securely%20connect%20Red%20Hat%20Integration%20Service%20Registry%20with%20Red%20Hat%20AMQ%20Streams" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F04%2F07%2Fsecurely-connect-red-hat-integration-service-registry-with-red-hat-amq-streams%2F&amp;#038;title=Securely%20connect%20Red%20Hat%20Integration%20Service%20Registry%20with%20Red%20Hat%20AMQ%20Streams" data-a2a-url="https://developers.redhat.com/blog/2021/04/07/securely-connect-red-hat-integration-service-registry-with-red-hat-amq-streams/" data-a2a-title="Securely connect Red Hat Integration Service Registry with Red Hat AMQ Streams"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/07/securely-connect-red-hat-integration-service-registry-with-red-hat-amq-streams/"&gt;Securely connect Red Hat Integration Service Registry with Red Hat AMQ Streams&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/PEfroeCHkfw" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Red Hat Integration Service Registry is a datastore based on the Apicurio open source project. In my previous article, I showed you how to integrate Spring Boot with Service Registry. In this article, you&amp;#8217;ll learn how to connect Service Registry to a secure Red Hat AMQ Streams cluster. Connecting Service Registry with AMQ Streams Service [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/04/07/securely-connect-red-hat-integration-service-registry-with-red-hat-amq-streams/"&gt;Securely connect Red Hat Integration Service Registry with Red Hat AMQ Streams&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/04/07/securely-connect-red-hat-integration-service-registry-with-red-hat-amq-streams/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">779427</post-id><dc:creator>Roman Martin Gil</dc:creator><dc:date>2021-04-07T07:00:20Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/04/07/securely-connect-red-hat-integration-service-registry-with-red-hat-amq-streams/</feedburner:origLink></entry></feed>
